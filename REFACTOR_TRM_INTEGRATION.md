# TRM Integration: Observable Transformation Architecture
**Humanizer Agent - Architectural Maturation Proposal**

**Version**: 1.0
**Date**: October 10, 2025
**Status**: üü° DESIGN COMPLETE - Ready for Implementation
**Estimated Timeline**: 6-7 weeks (30-35 dev days)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Philosophical Foundation](#philosophical-foundation)
3. [Technical Overview](#technical-overview)
4. [Architecture Integration](#architecture-integration)
5. [Database Schema](#database-schema)
6. [API Specification](#api-specification)
7. [ML Infrastructure](#ml-infrastructure)
8. [UI Components](#ui-components)
9. [MCP Integration](#mcp-integration)
10. [Implementation Plan](#implementation-plan)
11. [Success Metrics](#success-metrics)
12. [References](#references)

---

## Executive Summary

### The Core Innovation

The **Transformation Reading Model (TRM)** layer represents a fundamental architectural maturation that makes the **interpretive process observable**. Rather than treating transformation as a black box, TRM exposes the latent trajectory through which meaning evolves.

**Current Architecture:**
```
Content ‚Üí Embeddings ‚Üí Transformations ‚Üí Output
                       ‚Üë (black box)
```

**TRM Architecture:**
```
Content ‚Üí Embeddings ‚Üí Observable Transformation Process ‚Üí Output
                       ‚Üì
                  ‚Ä¢ Visible latent trajectory (œÅ evolution)
                  ‚Ä¢ Measurable stance (POVM probes)
                  ‚Ä¢ Four-corner perspectives (tetralemma)
                  ‚Ä¢ Provenance tracking (every step)
                  ‚Ä¢ User agency (adopt/discard/merge)
```

### What TRM Provides

1. **œÅ (rho) - Density Matrix**: A positive semi-definite (PSD) matrix representing the "understanding state" at each iteration step
2. **POVM Probes**: Positive Operator-Valued Measures that extract meaningful aspects (stance, tone, ontology, audience, etc.)
3. **Tetralemma Logic**: Four-corner perspectives (A, ¬¨A, both, neither) derived from catu·π£ko·π≠i Buddhist logic
4. **Tiny Recursive Model**: 5-19M parameter, 2-layer transformer that iteratively refines understanding
5. **Visible Trajectory**: Users observe meaning moving through latent space across recursion steps
6. **Auditable Provenance**: Complete record of every interpretive choice and transformation step

### Alignment with Consciousness Work

TRM directly implements the **Computational Madhyamaka** mission:

> "Make me smarter by helping me know my actual subjective me."

**How TRM achieves this:**

- **Makes construction visible**: Shows language interpretation as an active, constructed process (not passive)
- **Tetralemma integration**: Madhyamaka's four-cornered logic already exists in the API - TRM operationalizes it
- **Reveals agency**: Users see and choose between interpretive paths, witnessing their own subjectivity
- **No "seamless" hiding**: Deliberately exposes the gaps, pauses, and choices in meaning-making
- **Post-lexical awareness**: Shows understanding evolving beyond initial word-parsing

**This is not feature addition. This is making the invisible visible.**

---

## Philosophical Foundation

### Language as a Sense

From `CLAUDE.md`:
> "Language as a sense, not just communication. Embeddings reveal constructed meaning."

TRM makes this concrete:

```
Traditional View:           TRM View:
Text ‚Üí Meaning              Text ‚Üí Latent State (z) ‚Üí Observation (œÅ) ‚Üí POVM Measurement ‚Üí Meaning
   ‚Üë (automatic)                ‚Üë                        ‚Üë                    ‚Üë
                              (constructed)         (observable)        (measured)
```

### The Three Realms (Revisited)

1. **Corporeal Realm**: Raw sensory experience (text on screen)
2. **Subjective Realm**: Individual interpretation (œÅ state, POVM readings)
3. **Objective Realm**: Shared symbolic structures (embedded text)

**TRM operates at the boundary** between subjective and objective:
- Text exists objectively (embedding space)
- Interpretation is subjective (œÅ evolution, user choices)
- TRM makes the subjective interpretive process *observable* in objective terms

### Computational Madhyamaka

**Eternalism (Reification)**: Treating interpretations as inherently real
```python
# Eternalist assumption:
meaning = embedding  # "The embedding IS the meaning"
```

**Nihilism (Denial)**: Treating interpretations as meaningless
```python
# Nihilist assumption:
meaning = None  # "Nothing means anything"
```

**Middle Path (TRM)**: Interpretations arise dependently, function conventionally, empty ultimately
```python
# Middle path (TRM):
rho = construct_density_matrix(embedding, context, history)
meaning = measure_with_povm(rho, chosen_axes)
# Meaning is:
# - Constructed (not inherent)
# - Functional (not meaningless)
# - Observable (not hidden)
# - Provisional (not fixed)
```

### The Tetralemma (Catu·π£ko·π≠i)

Buddhist logic with four truth values:

1. **A**: Claim is true
2. **¬¨A**: Claim is false
3. **Both**: Claim is both true and false (paradox, context-dependent)
4. **Neither**: Claim transcends true/false (category error, mu)

**TRM Implementation:**

```python
# Four phase tokens in the model
phase_A = model(z, phase="A")         # Affirm the claim
phase_notA = model(z, phase="notA")   # Negate the claim
phase_both = model(z, phase="both")   # Hold paradox
phase_neither = model(z, phase="neither")  # Transcend binary
```

**Example:**

**Text**: "Language creates reality."

**Tetralemma Perspectives**:
- **A**: "Yes, linguistic categories shape perception and structure experience"
- **¬¨A**: "No, reality exists independently; language only labels pre-existing phenomena"
- **Both**: "Language co-creates reality at the subjective level while reality constrains language at the corporeal level"
- **Neither**: "The question presumes a subject-object split that doesn't hold upon investigation"

**User sees all four simultaneously** and can adopt/merge/discard.

---

## Technical Overview

### TRM Architecture (from arXiv:2510.04871v1)

**Original TRM Design** (Samsung SAIL Montreal):

- **Parameters**: 5-19M (optimal at 7M)
- **Layers**: 2 (empirically optimal - "less is more")
- **Hidden Size**: 512
- **Recursion Cycles**:
  - `H_cycles=3` (high-level reasoning)
  - `L_cycles=4` (low-level processing)
  - Total `n=6` recursion steps typical
- **Training**:
  - Deep supervision: T-1 steps without gradients, 1 step with backprop
  - EMA: 0.999
  - AdamW optimizer
  - Data augmentation: 1000x per example
  - Halt prediction: Binary CE loss
- **Inference**: Adaptive Computation Time (ACT) - stops when `q_hat > 0`

**Humanizer TRM Adaptation**:

We adapt TRM for **semantic transformation** (not puzzle-solving):

```python
class HumanizerTRM(nn.Module):
    """
    Tiny Recursive Model for semantic transformation.

    Adapts Samsung SAIL TRM for text understanding:
    - Input: Text embeddings (sentence-transformers)
    - Latent: Understanding state z ‚àà ‚Ñù^1024
    - Output: Refined text y, stance logits, halt probability
    - Phases: 4 phase tokens for tetralemma (A, ¬¨A, both, neither)
    """

    def __init__(
        self,
        d_model=1024,        # Larger hidden for semantic richness
        n_layers=2,          # Keep TRM optimal depth
        n_heads=8,
        n_phases=4,          # Tetralemma
        vocab_size=50000     # For text generation
    ):
        super().__init__()

        # Latent reasoning block (2-layer transformer)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=n_heads,
            dim_feedforward=d_model * 4,
            dropout=0.1,
            activation='gelu',
            batch_first=True
        )
        self.latent_block = nn.TransformerEncoder(
            encoder_layer,
            num_layers=n_layers
        )

        # Phase tokens for tetralemma
        self.phase_tokens = nn.Parameter(torch.randn(n_phases, d_model))

        # Output heads
        self.refine_head = nn.Linear(d_model, vocab_size)
        self.stance_head = nn.Linear(d_model, 4)  # [A, ¬¨A, both, neither]
        self.halt_head = nn.Linear(d_model, 1)

        # EMA for stable training
        self.ema_decay = 0.999
        self.register_buffer('ema_z', torch.zeros(1, d_model))

    def forward(self, x, y, z, phase_id=None, step=0):
        """
        Forward pass with optional phase conditioning.

        Args:
            x: Input text embedding [batch, seq_len, d]
            y: Current refined text embedding [batch, seq_len, d]
            z: Latent reasoning state [batch, d]
            phase_id: Optional phase (0=A, 1=¬¨A, 2=both, 3=neither)
            step: Current recursion step (for tracking)

        Returns:
            y_new: Refined text logits [batch, seq_len, vocab]
            z_new: Updated latent state [batch, d]
            stance: Tetralemma stance logits [batch, 4]
            halt_p: Halt probability [batch, 1]
        """
        batch_size = x.size(0)

        # Expand z to sequence
        z_seq = z.unsqueeze(1).expand(-1, x.size(1), -1)

        # Concatenate input, current output, and latent state
        combined = torch.cat([x, y, z_seq], dim=-1)  # [batch, seq_len, 3*d]

        # Project to d_model
        combined = self.input_proj(combined)

        # Add phase token if specified
        if phase_id is not None:
            phase_emb = self.phase_tokens[phase_id].unsqueeze(0).unsqueeze(0)
            combined = combined + phase_emb

        # Recursive latent update (2-layer transformer)
        z_new_seq = self.latent_block(combined)

        # Pool to get new latent state
        z_new = z_new_seq.mean(dim=1)  # [batch, d]

        # Update EMA
        if self.training:
            self.ema_z = self.ema_decay * self.ema_z + (1 - self.ema_decay) * z_new.mean(0, keepdim=True)

        # Generate outputs
        y_new = self.refine_head(z_new_seq)  # [batch, seq_len, vocab]
        stance = self.stance_head(z_new)      # [batch, 4]
        halt_p = torch.sigmoid(self.halt_head(z_new))  # [batch, 1]

        return y_new, z_new, stance, halt_p
```

### œÅ (Rho) Construction

**Mathematical Foundation:**

A **density matrix** œÅ is:
1. **Positive Semi-Definite (PSD)**: All eigenvalues ‚â• 0
2. **Unit Trace**: tr(œÅ) = 1
3. **Hermitian**: œÅ = œÅ‚Ä†

In quantum mechanics, œÅ represents a mixed state. Here, we use it as a **covariance-like representation** of the latent understanding state.

**Construction Algorithm:**

```python
def construct_rho(z, layer_features, rank=32):
    """
    Construct density matrix œÅ from latent state.

    Args:
        z: Latent state [batch, d_model]
        layer_features: Features from transformer layers [batch, seq_len, d_model]
        rank: Target rank for low-rank approximation

    Returns:
        rho: Density matrix [batch, rank, rank]
        eigvals: Top-r eigenvalues [batch, rank]
        eigvecs: Top-r eigenvectors [batch, d_model, rank]
    """
    batch_size, seq_len, d = layer_features.shape

    # 1. Extract relevant features (value states from attention)
    H = layer_features  # [batch, seq_len, d]

    # 2. Compute scatter/covariance matrix
    H_centered = H - H.mean(dim=1, keepdim=True)
    S = torch.matmul(H_centered.transpose(1, 2), H_centered) / seq_len  # [batch, d, d]

    # Optional: Ledoit-Wolf shrinkage for stability
    trace_S = torch.diagonal(S, dim1=-2, dim2=-1).sum(dim=-1, keepdim=True)
    identity = torch.eye(d, device=S.device).unsqueeze(0)
    shrinkage_target = (trace_S / d).unsqueeze(-1) * identity
    alpha = 0.1  # Shrinkage parameter
    S = (1 - alpha) * S + alpha * shrinkage_target

    # 3. Low-rank approximation via eigendecomposition
    eigvals, eigvecs = torch.linalg.eigh(S)  # [batch, d], [batch, d, d]

    # 4. Keep top-r eigenvalues/eigenvectors
    eigvals_top = eigvals[:, -rank:]  # [batch, rank]
    eigvecs_top = eigvecs[:, :, -rank:]  # [batch, d, rank]

    # 5. Clamp negative eigenvalues to zero (ensure PSD)
    eigvals_top = torch.clamp(eigvals_top, min=0.0)

    # 6. Normalize to unit trace
    trace = eigvals_top.sum(dim=-1, keepdim=True)
    eigvals_top = eigvals_top / (trace + 1e-8)

    # 7. Reconstruct low-rank œÅ
    rho = torch.matmul(
        eigvecs_top * eigvals_top.unsqueeze(1),
        eigvecs_top.transpose(-2, -1)
    )  # [batch, d, d] but rank-r

    # For storage, keep only eigensystem (more compact)
    return rho, eigvals_top, eigvecs_top


def rho_to_bytes(eigvals, eigvecs):
    """Serialize œÅ eigensystem for database storage."""
    eigvals_np = eigvals.cpu().numpy().astype(np.float32)
    eigvecs_np = eigvecs.cpu().numpy().astype(np.float32)

    # Concatenate and serialize
    data = np.concatenate([
        eigvals_np.flatten(),
        eigvecs_np.flatten()
    ])
    return data.tobytes()


def bytes_to_rho(data, d_model=1024, rank=32):
    """Deserialize œÅ eigensystem from database."""
    arr = np.frombuffer(data, dtype=np.float32)

    # Split into eigenvalues and eigenvectors
    eigvals = arr[:rank].reshape(1, rank)
    eigvecs = arr[rank:].reshape(1, d_model, rank)

    # Reconstruct œÅ
    eigvals_torch = torch.from_numpy(eigvals)
    eigvecs_torch = torch.from_numpy(eigvecs)

    rho = torch.matmul(
        eigvecs_torch * eigvals_torch.unsqueeze(1),
        eigvecs_torch.transpose(-2, -1)
    )

    return rho, eigvals_torch, eigvecs_torch
```

**Why Low-Rank?**

Full œÅ is d√ód = 1024√ó1024 = 4MB per step (too large). Low-rank approximation with r=32:
- Storage: 32 eigenvalues + 1024√ó32 eigenvectors = 32 + 32,768 = 32,800 floats √ó 4 bytes = 131 KB
- Captures top-r principal directions (most variance)
- Stable, efficient, interpretable

### POVM Probes

**Positive Operator-Valued Measure (POVM):**

A set of PSD matrices {E‚ÇÅ, E‚ÇÇ, ..., E‚Çô} where:
1. Each E·µ¢ is PSD
2. ‚àë·µ¢ E·µ¢ = I (identity - completeness)

**Measurement**: Given œÅ, probability of outcome i is:

```
p(i) = tr(E·µ¢ œÅ)
```

**Implementation:**

```python
class POVMPack(nn.Module):
    """
    POVM measurement pack.

    A collection of PSD projection matrices that measure
    different aspects of the density matrix œÅ.
    """

    def __init__(self, d_model=1024, n_axes=4, pack_name="tetralemma"):
        super().__init__()
        self.pack_name = pack_name
        self.n_axes = n_axes

        # Parameterize E_i = B_i @ B_i^T (guarantees PSD)
        self.B = nn.Parameter(torch.randn(n_axes, d_model, d_model // 4))

        # Axis names
        if pack_name == "tetralemma":
            self.axis_names = ["A", "¬¨A", "both", "neither"]
        elif pack_name == "tone":
            self.axis_names = ["analytical", "critical", "empathic", "playful"]
        elif pack_name == "ontology":
            self.axis_names = ["corporeal", "subjective", "objective", "mixed"]
        elif pack_name == "pragmatics":
            self.axis_names = ["clarity", "coherence", "evidence", "charity"]
        elif pack_name == "audience":
            self.axis_names = ["expert", "general", "student", "editorial"]
        else:
            self.axis_names = [f"axis_{i}" for i in range(n_axes)]

    def forward(self, rho):
        """
        Measure œÅ with this POVM pack.

        Args:
            rho: Density matrix [batch, d, d]

        Returns:
            probs: Probabilities [batch, n_axes]
            readings: Dict mapping axis names to probabilities
        """
        # Construct E_i = B_i @ B_i^T
        E = torch.matmul(self.B, self.B.transpose(-2, -1))  # [n_axes, d, d]

        # Ensure completeness: normalize so ‚àëE_i = I
        E_sum = E.sum(dim=0)  # [d, d]
        identity = torch.eye(rho.size(-1), device=rho.device)
        E = E * (identity.sum() / E_sum.diag().sum())

        # Measure: p_i = tr(E_i @ œÅ)
        # Use einsum for batched trace
        probs = torch.einsum('ijk,bjk->bi', E, rho)  # [batch, n_axes]

        # Normalize to valid probabilities
        probs = torch.clamp(probs, min=0.0)
        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)

        # Create readings dict
        readings = {
            name: probs[:, i].cpu().numpy().tolist()
            for i, name in enumerate(self.axis_names)
        }

        return probs, readings


# Predefined POVM packs
POVM_PACKS = {
    "tetralemma": POVMPack(pack_name="tetralemma"),
    "tone": POVMPack(pack_name="tone"),
    "ontology": POVMPack(pack_name="ontology"),
    "pragmatics": POVMPack(pack_name="pragmatics"),
    "audience": POVMPack(pack_name="audience")
}
```

**Training POVM Heads:**

```python
def train_povm_heads(model, dataloader, optimizer, n_epochs=10):
    """
    Train POVM heads via contrastive learning.

    Goal: Make œÅ separable along meaningful semantic axes.

    Data: Pairs of texts with known differences:
    - (text_analytical, text_empathic) ‚Üí tone pack
    - (text_corporeal, text_objective) ‚Üí ontology pack
    - (text_expert, text_general) ‚Üí audience pack
    """

    for epoch in range(n_epochs):
        for batch in dataloader:
            # batch: (text1, text2, pack_name, axis_diff)
            text1, text2, pack_name, axis_diff = batch

            # Get œÅ for both texts
            z1, rho1 = model.encode_and_rho(text1)
            z2, rho2 = model.encode_and_rho(text2)

            # Measure with relevant POVM pack
            pack = POVM_PACKS[pack_name]
            probs1, _ = pack(rho1)
            probs2, _ = pack(rho2)

            # Contrastive loss: Maximize difference along axis_diff
            axis_idx = pack.axis_names.index(axis_diff)

            # Want probs1[axis_idx] high, probs2[axis_idx] low (or vice versa)
            loss = -torch.abs(probs1[:, axis_idx] - probs2[:, axis_idx]).mean()

            # Also enforce consistency: Same text ‚Üí same œÅ
            consistency_loss = F.mse_loss(rho1, rho1)  # (trivial, but with augmentation)

            total_loss = loss + 0.1 * consistency_loss

            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
```

---

## Architecture Integration

### Integration with Existing Systems

#### 1. Unified Content Architecture

**Current Plan** (from `UNIFIED_ARCHITECTURE_SPEC.md`):
- Consolidate to `content_items` table
- Polymorphic type handlers
- Unified API at `/api/content/*`

**TRM Integration:**

```python
# Reading sessions operate on ContentItems
from models.unified_content import ContentItem

class ReadingSession(Base):
    __tablename__ = "reading_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # Link to content item being read
    content_item_id = Column(UUID(as_uuid=True), ForeignKey('content_items.id'))

    # OR: Direct text (if ad-hoc reading)
    original_text = Column(Text, nullable=True)

    # ... rest of fields


# When reading session completes, save as artifact
async def finalize_reading_session(session_id: UUID):
    session = await db.get(ReadingSession, session_id)
    steps = await db.query(ReadingStep).filter_by(session_id=session_id).all()

    # Create artifact from final output
    final_step = max(steps, key=lambda s: s.step)

    artifact = ContentItem(
        content_type="artifact",
        source_type="trm_reading",
        source_id=str(session_id),
        title=f"Reading Session: {session.original_text[:50]}...",
        content=final_step.y_text,
        metadata={
            "reading_session_id": str(session_id),
            "total_steps": len(steps),
            "final_halt_p": final_step.halt_p,
            "stance_evolution": [s.stance for s in steps]
        }
    )

    await db.add(artifact)

    # Create relationship
    relationship = ContentRelationship(
        from_item_id=session.content_item_id,
        to_item_id=artifact.id,
        relationship_type="transforms_via_reading",
        metadata={
            "reading_id": str(session_id),
            "steps": len(steps)
        }
    )

    await db.add(relationship)
    await db.commit()
```

#### 2. Madhyamaka API Integration

**TRM as Madhyamaka Instrument:**

```python
# services/madhyamaka_reading_bridge.py

async def analyze_reading_trace_madhyamaka(reading_id: UUID):
    """
    Analyze a reading session trace through Madhyamaka lens.

    Returns:
    - Eternalism evolution (reification decreasing over steps?)
    - Nihilism risk (emptiness misunderstood as nothingness?)
    - Middle path convergence (balanced tetralemma stance?)
    - Teaching moments (when to intervene with guidance)
    """

    steps = await db.query(ReadingStep).filter_by(session_id=reading_id).order_by(ReadingStep.step).all()

    eternalism_scores = []
    nihilism_scores = []
    middle_path_scores = []

    for step in steps:
        # Use Madhyamaka detection on each step's text
        eternalism = await madhyamaka_service.detect_eternalism(step.y_text)
        nihilism = await madhyamaka_service.detect_nihilism(step.y_text)
        middle_path = await madhyamaka_service.detect_middle_path_proximity(step.y_text)

        eternalism_scores.append(eternalism['confidence'])
        nihilism_scores.append(nihilism['confidence'])
        middle_path_scores.append(middle_path['middle_path_score'])

    # Analyze trends
    eternalism_trend = "decreasing" if eternalism_scores[-1] < eternalism_scores[0] else "increasing"
    middle_path_trend = "converging" if middle_path_scores[-1] > middle_path_scores[0] else "diverging"

    # Generate teaching moments
    teaching_moments = []
    for i, step in enumerate(steps):
        if nihilism_scores[i] > 0.7:
            teaching_moments.append({
                "step": i,
                "issue": "nihilism_risk",
                "guidance": "Two truths practice recommended",
                "step_text": step.y_text
            })

        if eternalism_scores[i] > 0.8 and i > 2:  # Persisting reification
            teaching_moments.append({
                "step": i,
                "issue": "persistent_eternalism",
                "guidance": "Dependent origination inquiry",
                "step_text": step.y_text
            })

    return {
        "eternalism_evolution": eternalism_scores,
        "eternalism_trend": eternalism_trend,
        "nihilism_risks": [i for i, s in enumerate(nihilism_scores) if s > 0.6],
        "middle_path_convergence": middle_path_trend,
        "middle_path_scores": middle_path_scores,
        "teaching_moments": teaching_moments
    }
```

#### 3. Transformation Pipeline Integration

**TRM as Transformation Visualizer:**

Existing transformations (Persona, Humanizer, etc.) operate as black boxes. TRM can **visualize their internal dynamics**:

```python
# services/transformation_reading.py

async def apply_transformation_with_reading(
    text: str,
    transformation_type: str,  # "persona", "humanizer", "madhyamaka"
    **kwargs
):
    """
    Apply transformation while tracking via TRM reading session.

    Instead of:
        output = transform(text)

    Do:
        reading_session = start_reading(text, task=f"Apply {transformation_type}")
        for step in range(max_steps):
            step_output = reading_step(reading_session.id)
            # Track œÅ evolution, stance changes, corner views
        output = step_output.y_text

    User sees HOW the transformation happened, not just final result.
    """

    # Start reading session with transformation task
    session = await reading_service.start_reading(
        text=text,
        task=f"Transform via {transformation_type}",
        persona=kwargs.get('persona'),
        namespace=kwargs.get('namespace'),
        style=kwargs.get('style')
    )

    # Run TRM steps until halt
    trajectory = []
    while not session.halted and session.current_step < session.max_steps:
        step_result = await reading_service.step_reading(session.id)

        trajectory.append({
            "step": step_result.step,
            "text": step_result.y_text,
            "rho_delta": step_result.rho_delta,
            "stance": step_result.stance,
            "halt_p": step_result.halt_p
        })

        # Check halt condition
        if step_result.halt_p > session.halt_threshold:
            await reading_service.halt_session(session.id)
            break

    # Return final output + full trajectory
    return {
        "output": trajectory[-1]["text"],
        "reading_session_id": session.id,
        "trajectory": trajectory,
        "total_steps": len(trajectory),
        "madhyamaka_analysis": await analyze_reading_trace_madhyamaka(session.id)
    }
```

---

## Database Schema

### Complete Schema Definitions

#### 1. `reading_sessions`

```sql
CREATE TABLE reading_sessions (
  -- Identity
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

  -- Input
  content_item_id UUID REFERENCES content_items(id) ON DELETE SET NULL,
  original_text TEXT,
  task TEXT,
  persona TEXT,
  namespace TEXT,
  style TEXT,

  -- Configuration
  max_steps INTEGER DEFAULT 10,
  n_recursions INTEGER DEFAULT 6,
  halt_threshold FLOAT DEFAULT 0.95,

  -- State
  current_step INTEGER DEFAULT 0,
  halted BOOLEAN DEFAULT FALSE,
  halt_reason TEXT,  -- 'threshold_reached', 'max_steps', 'user_stopped'

  -- Metadata
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  created_by UUID REFERENCES users(id),

  -- Constraints
  CONSTRAINT valid_halt_threshold CHECK (halt_threshold BETWEEN 0.0 AND 1.0),
  CONSTRAINT valid_n_recursions CHECK (n_recursions BETWEEN 1 AND 20),
  CONSTRAINT text_or_content_item CHECK (
    (original_text IS NOT NULL) OR (content_item_id IS NOT NULL)
  )
);

CREATE INDEX idx_reading_sessions_user ON reading_sessions(created_by);
CREATE INDEX idx_reading_sessions_content_item ON reading_sessions(content_item_id);
CREATE INDEX idx_reading_sessions_created ON reading_sessions(created_at DESC);
CREATE INDEX idx_reading_sessions_halted ON reading_sessions(halted) WHERE halted = FALSE;
```

#### 2. `reading_steps`

```sql
CREATE TABLE reading_steps (
  -- Identity
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES reading_sessions(id) ON DELETE CASCADE,
  step INTEGER NOT NULL,

  -- Content evolution
  y_text TEXT NOT NULL,
  dy_summary TEXT,
  token_count INTEGER,

  -- Latent state (pgvector)
  z_vec VECTOR(1024),

  -- Density matrix (compressed eigensystem)
  rho_lowrank BYTEA NOT NULL,
  rho_rank INTEGER DEFAULT 32,
  rho_trace FLOAT,
  rho_norm FLOAT,

  -- Measurements
  povm_readings JSONB NOT NULL,  -- {pack_name: {axis: probability}}
  stance JSONB NOT NULL,         -- {A: p, notA: p, both: p, neither: p}
  halt_p FLOAT NOT NULL,

  -- Corner views (phase-conditioned outputs)
  corner_views JSONB,  -- {A: text, notA: text, both: text, neither: text}

  -- Deltas from previous step
  rho_delta FLOAT,  -- ||œÅ_t - œÅ_{t-1}||_F (Frobenius norm)
  stance_delta JSONB,  -- {A: Œîp, notA: Œîp, ...}

  -- Provenance
  diffs JSONB,  -- Semantic diffs (OT-style JSON patches)
  applied_patches JSONB,  -- User-applied patches at this step

  -- Timestamps
  created_at TIMESTAMP DEFAULT NOW(),
  inference_time_ms INTEGER,  -- How long this step took

  -- Constraints
  UNIQUE(session_id, step),
  CONSTRAINT valid_step CHECK (step >= 0),
  CONSTRAINT valid_halt_p CHECK (halt_p BETWEEN 0.0 AND 1.0),
  CONSTRAINT valid_rho_rank CHECK (rho_rank > 0 AND rho_rank <= 1024)
);

CREATE INDEX idx_reading_steps_session ON reading_steps(session_id, step);
CREATE INDEX idx_reading_steps_z_ivfflat ON reading_steps
  USING ivfflat (z_vec vector_cosine_ops) WITH (lists = 100);
CREATE INDEX idx_reading_steps_halt_p ON reading_steps(halt_p DESC);
CREATE INDEX idx_reading_steps_stance ON reading_steps USING GIN(stance);
CREATE INDEX idx_reading_steps_povm ON reading_steps USING GIN(povm_readings);
```

#### 3. `reading_snapshots`

```sql
CREATE TABLE reading_snapshots (
  -- Identity
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES reading_sessions(id) ON DELETE CASCADE,
  step INTEGER NOT NULL,

  -- Export data
  artifact_id UUID REFERENCES content_items(id),  -- If saved as artifact
  snapshot_data JSONB,  -- Full UI state export
  snapshot_type TEXT,   -- 'manual', 'auto', 'completion'

  -- Metadata
  created_at TIMESTAMP DEFAULT NOW(),
  created_by UUID REFERENCES users(id),

  CONSTRAINT valid_snapshot_type CHECK (
    snapshot_type IN ('manual', 'auto', 'completion')
  )
);

CREATE INDEX idx_reading_snapshots_session ON reading_snapshots(session_id);
CREATE INDEX idx_reading_snapshots_artifact ON reading_snapshots(artifact_id);
```

#### 4. `reading_provenance`

```sql
CREATE TABLE reading_provenance (
  -- Identity
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES reading_sessions(id) ON DELETE CASCADE,
  step INTEGER NOT NULL,

  -- Action details
  action TEXT NOT NULL,  -- 'apply_corner:A', 'apply_edit:coherence', 'user_override'
  patch JSONB NOT NULL,  -- JSON patch (RFC 6902)

  -- Metadata
  created_at TIMESTAMP DEFAULT NOW(),
  created_by UUID REFERENCES users(id),

  CONSTRAINT valid_action CHECK (
    action ~ '^(apply_corner|apply_edit|user_override|merge)'
  )
);

CREATE INDEX idx_reading_provenance_session ON reading_provenance(session_id, step);
CREATE INDEX idx_reading_provenance_action ON reading_provenance(action);
CREATE INDEX idx_reading_provenance_created ON reading_provenance(created_at DESC);
```

#### 5. Additional Helper Tables

**POVM Pack Configurations**:

```sql
CREATE TABLE povm_packs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT UNIQUE NOT NULL,
  description TEXT,
  axis_names TEXT[] NOT NULL,
  weights_data BYTEA,  -- Serialized B matrices
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Default packs
INSERT INTO povm_packs (name, description, axis_names) VALUES
  ('tetralemma', 'Four-cornered logic', ARRAY['A', '¬¨A', 'both', 'neither']),
  ('tone', 'Emotional tone analysis', ARRAY['analytical', 'critical', 'empathic', 'playful']),
  ('ontology', 'Ontological framing', ARRAY['corporeal', 'subjective', 'objective', 'mixed']),
  ('pragmatics', 'Pragmatic quality', ARRAY['clarity', 'coherence', 'evidence', 'charity']),
  ('audience', 'Target audience', ARRAY['expert', 'general', 'student', 'editorial']);
```

**User Reading Preferences**:

```sql
CREATE TABLE user_reading_preferences (
  user_id UUID PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE,
  default_max_steps INTEGER DEFAULT 10,
  default_halt_threshold FLOAT DEFAULT 0.95,
  favorite_povm_packs TEXT[] DEFAULT ARRAY['tetralemma', 'tone'],
  auto_save_snapshots BOOLEAN DEFAULT TRUE,
  show_tutorial_animations BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

### Migration Script

```python
# backend/alembic/versions/00X_add_reading_tables.py

"""Add TRM reading tables

Revision ID: 00X
Revises: 006
Create Date: 2025-10-10

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import UUID, JSONB, VECTOR

revision = '00X'
down_revision = '006'
branch_labels = None
depends_on = None


def upgrade():
    # Create reading_sessions table
    op.create_table(
        'reading_sessions',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('content_item_id', UUID(as_uuid=True), sa.ForeignKey('content_items.id', ondelete='SET NULL')),
        sa.Column('original_text', sa.Text, nullable=True),
        sa.Column('task', sa.Text, nullable=True),
        sa.Column('persona', sa.Text, nullable=True),
        sa.Column('namespace', sa.Text, nullable=True),
        sa.Column('style', sa.Text, nullable=True),
        sa.Column('max_steps', sa.Integer, default=10),
        sa.Column('n_recursions', sa.Integer, default=6),
        sa.Column('halt_threshold', sa.Float, default=0.95),
        sa.Column('current_step', sa.Integer, default=0),
        sa.Column('halted', sa.Boolean, default=False),
        sa.Column('halt_reason', sa.Text, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('updated_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('created_by', UUID(as_uuid=True), sa.ForeignKey('users.id')),
    )

    # Create reading_steps table
    op.create_table(
        'reading_steps',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('session_id', UUID(as_uuid=True), sa.ForeignKey('reading_sessions.id', ondelete='CASCADE'), nullable=False),
        sa.Column('step', sa.Integer, nullable=False),
        sa.Column('y_text', sa.Text, nullable=False),
        sa.Column('dy_summary', sa.Text, nullable=True),
        sa.Column('token_count', sa.Integer, nullable=True),
        sa.Column('z_vec', VECTOR(1024), nullable=True),
        sa.Column('rho_lowrank', sa.LargeBinary, nullable=False),
        sa.Column('rho_rank', sa.Integer, default=32),
        sa.Column('rho_trace', sa.Float, nullable=True),
        sa.Column('rho_norm', sa.Float, nullable=True),
        sa.Column('povm_readings', JSONB, nullable=False),
        sa.Column('stance', JSONB, nullable=False),
        sa.Column('halt_p', sa.Float, nullable=False),
        sa.Column('corner_views', JSONB, nullable=True),
        sa.Column('rho_delta', sa.Float, nullable=True),
        sa.Column('stance_delta', JSONB, nullable=True),
        sa.Column('diffs', JSONB, nullable=True),
        sa.Column('applied_patches', JSONB, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('inference_time_ms', sa.Integer, nullable=True),
        sa.UniqueConstraint('session_id', 'step', name='uq_session_step')
    )

    # Create reading_snapshots table
    op.create_table(
        'reading_snapshots',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('session_id', UUID(as_uuid=True), sa.ForeignKey('reading_sessions.id', ondelete='CASCADE'), nullable=False),
        sa.Column('step', sa.Integer, nullable=False),
        sa.Column('artifact_id', UUID(as_uuid=True), sa.ForeignKey('content_items.id')),
        sa.Column('snapshot_data', JSONB, nullable=True),
        sa.Column('snapshot_type', sa.String(50), nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('created_by', UUID(as_uuid=True), sa.ForeignKey('users.id')),
    )

    # Create reading_provenance table
    op.create_table(
        'reading_provenance',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('session_id', UUID(as_uuid=True), sa.ForeignKey('reading_sessions.id', ondelete='CASCADE'), nullable=False),
        sa.Column('step', sa.Integer, nullable=False),
        sa.Column('action', sa.Text, nullable=False),
        sa.Column('patch', JSONB, nullable=False),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('created_by', UUID(as_uuid=True), sa.ForeignKey('users.id')),
    )

    # Create povm_packs table
    op.create_table(
        'povm_packs',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('name', sa.Text, unique=True, nullable=False),
        sa.Column('description', sa.Text, nullable=True),
        sa.Column('axis_names', sa.ARRAY(sa.Text), nullable=False),
        sa.Column('weights_data', sa.LargeBinary, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('updated_at', sa.TIMESTAMP, default=sa.func.now()),
    )

    # Create user_reading_preferences table
    op.create_table(
        'user_reading_preferences',
        sa.Column('user_id', UUID(as_uuid=True), sa.ForeignKey('users.id', ondelete='CASCADE'), primary_key=True),
        sa.Column('default_max_steps', sa.Integer, default=10),
        sa.Column('default_halt_threshold', sa.Float, default=0.95),
        sa.Column('favorite_povm_packs', sa.ARRAY(sa.Text), default=['tetralemma', 'tone']),
        sa.Column('auto_save_snapshots', sa.Boolean, default=True),
        sa.Column('show_tutorial_animations', sa.Boolean, default=True),
        sa.Column('created_at', sa.TIMESTAMP, default=sa.func.now()),
        sa.Column('updated_at', sa.TIMESTAMP, default=sa.func.now()),
    )

    # Create indexes
    op.create_index('idx_reading_sessions_user', 'reading_sessions', ['created_by'])
    op.create_index('idx_reading_sessions_content_item', 'reading_sessions', ['content_item_id'])
    op.create_index('idx_reading_sessions_created', 'reading_sessions', ['created_at'], postgresql_ops={'created_at': 'DESC'})

    op.create_index('idx_reading_steps_session', 'reading_steps', ['session_id', 'step'])
    op.create_index('idx_reading_steps_halt_p', 'reading_steps', ['halt_p'], postgresql_ops={'halt_p': 'DESC'})

    # Create ivfflat index for z_vec (pgvector)
    op.execute("""
        CREATE INDEX idx_reading_steps_z_ivfflat ON reading_steps
        USING ivfflat (z_vec vector_cosine_ops) WITH (lists = 100);
    """)

    # Create GIN indexes for JSONB
    op.create_index('idx_reading_steps_stance', 'reading_steps', ['stance'], postgresql_using='gin')
    op.create_index('idx_reading_steps_povm', 'reading_steps', ['povm_readings'], postgresql_using='gin')

    op.create_index('idx_reading_snapshots_session', 'reading_snapshots', ['session_id'])
    op.create_index('idx_reading_snapshots_artifact', 'reading_snapshots', ['artifact_id'])

    op.create_index('idx_reading_provenance_session', 'reading_provenance', ['session_id', 'step'])
    op.create_index('idx_reading_provenance_action', 'reading_provenance', ['action'])

    # Insert default POVM packs
    op.execute("""
        INSERT INTO povm_packs (id, name, description, axis_names) VALUES
        (gen_random_uuid(), 'tetralemma', 'Four-cornered logic (catu·π£ko·π≠i)', ARRAY['A', '¬¨A', 'both', 'neither']),
        (gen_random_uuid(), 'tone', 'Emotional tone analysis', ARRAY['analytical', 'critical', 'empathic', 'playful']),
        (gen_random_uuid(), 'ontology', 'Ontological framing', ARRAY['corporeal', 'subjective', 'objective', 'mixed']),
        (gen_random_uuid(), 'pragmatics', 'Pragmatic quality', ARRAY['clarity', 'coherence', 'evidence', 'charity']),
        (gen_random_uuid(), 'audience', 'Target audience', ARRAY['expert', 'general', 'student', 'editorial']);
    """)


def downgrade():
    op.drop_table('user_reading_preferences')
    op.drop_table('povm_packs')
    op.drop_table('reading_provenance')
    op.drop_table('reading_snapshots')
    op.drop_table('reading_steps')
    op.drop_table('reading_sessions')
```

---

## API Specification

[*Continuing in next section due to length...*]

### FastAPI Routes: `/api/reading/*`

**File**: `backend/api/reading_routes.py`

```python
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Optional
from uuid import UUID
from pydantic import BaseModel, Field

from models.database import get_db
from services import reading_service
from services.auth import get_current_user

router = APIRouter(prefix="/api/reading", tags=["reading"])


# ============================================================================
# Request/Response Schemas
# ============================================================================

class StartReadingRequest(BaseModel):
    """Request to start a new reading session."""
    text: Optional[str] = None
    content_item_id: Optional[UUID] = None
    task: Optional[str] = None
    persona: Optional[str] = None
    namespace: Optional[str] = None
    style: Optional[str] = None
    max_steps: int = Field(default=10, ge=1, le=50)
    n_recursions: int = Field(default=6, ge=1, le=20)
    halt_threshold: float = Field(default=0.95, ge=0.0, le=1.0)

    class Config:
        json_schema_extra = {
            "example": {
                "text": "Language creates reality.",
                "task": "Analyze tetralemma stance evolution",
                "max_steps": 10,
                "halt_threshold": 0.95
            }
        }


class StartReadingResponse(BaseModel):
    """Response from starting a reading session."""
    reading_id: UUID
    step: int
    y: str
    rho_meta: dict
    povm_readings: dict
    stance: dict
    halt_p: float


class StepReadingRequest(BaseModel):
    """Request to advance reading session by one step."""
    reading_id: UUID


class StepReadingResponse(BaseModel):
    """Response from reading step."""
    step: int
    y: str
    dy_summary: str
    rho_delta: float
    povm_readings: dict
    stance: dict
    stance_delta: dict
    halt_p: float
    corner_views: dict
    inference_time_ms: int


class MeasureReadingRequest(BaseModel):
    """Request to measure reading with specific POVM pack."""
    reading_id: UUID
    povm_pack: str
    custom_axes: Optional[List[str]] = None


class MeasureReadingResponse(BaseModel):
    """Response from POVM measurement."""
    step: int
    readings: List[dict]
    rho_projection: dict


class ApplyPatchRequest(BaseModel):
    """Request to apply user selections."""
    reading_id: UUID
    apply: List[str]  # ["corner:A", "corner:both", "edit:coherence"]


class ApplyPatchResponse(BaseModel):
    """Response from applying patches."""
    step: int
    y: str
    provenance_patch: dict


class ReadingTraceResponse(BaseModel):
    """Full trace of reading session."""
    steps: List[dict]
    metrics: dict
    snapshots: List[dict]


# ============================================================================
# Endpoints
# ============================================================================

@router.post("/start", response_model=StartReadingResponse)
async def start_reading(
    request: StartReadingRequest,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Start a new reading session.

    Initializes TRM with input text and returns initial state:
    - y‚ÇÄ: Initial text (potentially preprocessed)
    - œÅ‚ÇÄ: Initial density matrix metadata
    - POVM readings for all default packs
    - Initial stance (tetralemma)
    - Initial halt probability
    """

    # Validate input
    if not request.text and not request.content_item_id:
        raise HTTPException(400, "Either 'text' or 'content_item_id' required")

    # Start reading session
    result = await reading_service.start(
        db=db,
        user_id=current_user.id,
        text=request.text,
        content_item_id=request.content_item_id,
        task=request.task,
        persona=request.persona,
        namespace=request.namespace,
        style=request.style,
        max_steps=request.max_steps,
        n_recursions=request.n_recursions,
        halt_threshold=request.halt_threshold
    )

    return result


@router.post("/step", response_model=StepReadingResponse)
async def step_reading(
    request: StepReadingRequest,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Advance reading session by one TRM step.

    Performs:
    1. n_recursions iterations of TRM latent update
    2. Four phase passes (A, ¬¨A, both, neither) ‚Üí corner views
    3. Single refine pass ‚Üí y‚Çú
    4. Compute œÅ‚Çú from final features
    5. Measure with all POVM packs
    6. Compute stance and halt probability
    7. Calculate deltas from previous step

    Returns updated state and corner views.
    """

    # Check authorization
    session = await reading_service.get_session(db, request.reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    if session.halted:
        raise HTTPException(400, f"Session already halted: {session.halt_reason}")

    # Perform step
    result = await reading_service.step(
        db=db,
        session_id=request.reading_id
    )

    return result


@router.post("/measure", response_model=MeasureReadingResponse)
async def measure_reading(
    request: MeasureReadingRequest,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Measure reading state with specific POVM pack.

    Allows on-demand measurement with any POVM pack,
    including custom packs if axes are specified.
    """

    # Check authorization
    session = await reading_service.get_session(db, request.reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    # Measure
    result = await reading_service.measure(
        db=db,
        session_id=request.reading_id,
        povm_pack=request.povm_pack,
        custom_axes=request.custom_axes
    )

    return result


@router.post("/apply", response_model=ApplyPatchResponse)
async def apply_patch(
    request: ApplyPatchRequest,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Apply user-selected patches to current reading state.

    Supported actions:
    - corner:A, corner:notA, corner:both, corner:neither
      ‚Üí Adopt text from specific corner view
    - merge:A+both
      ‚Üí Merge multiple corner views
    - edit:coherence, edit:clarity, ...
      ‚Üí Apply POVM-suggested edits

    Records provenance for all applied patches.
    """

    # Check authorization
    session = await reading_service.get_session(db, request.reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    # Apply patches
    result = await reading_service.apply_patches(
        db=db,
        session_id=request.reading_id,
        actions=request.apply
    )

    return result


@router.get("/{reading_id}/trace", response_model=ReadingTraceResponse)
async def get_reading_trace(
    reading_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Get complete trace of reading session.

    Returns:
    - All steps with summaries
    - Metrics: œÅ norms, divergences, halt curve
    - Snapshots (if any)
    - Madhyamaka analysis (if applicable)
    """

    # Check authorization
    session = await reading_service.get_session(db, reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    # Get trace
    result = await reading_service.get_trace(
        db=db,
        session_id=reading_id
    )

    return result


@router.delete("/{reading_id}")
async def delete_reading_session(
    reading_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Delete a reading session and all associated data."""

    # Check authorization
    session = await reading_service.get_session(db, reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    await reading_service.delete(db, reading_id)

    return {"message": "Reading session deleted"}


@router.post("/{reading_id}/snapshot")
async def create_snapshot(
    reading_id: UUID,
    snapshot_type: str = "manual",
    save_as_artifact: bool = False,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    Create a snapshot of current reading state.

    Optionally saves final output as an artifact in content_items.
    """

    # Check authorization
    session = await reading_service.get_session(db, reading_id)
    if session.created_by != current_user.id:
        raise HTTPException(403, "Not authorized")

    result = await reading_service.create_snapshot(
        db=db,
        session_id=reading_id,
        snapshot_type=snapshot_type,
        save_as_artifact=save_as_artifact,
        user_id=current_user.id
    )

    return result


@router.get("/health")
async def reading_health():
    """Health check for reading service."""
    return {
        "status": "healthy",
        "service": "reading",
        "message": "The reading process neither exists nor does not exist. Yet this API responds."
    }
```

---

## UI Components

### Component Architecture

**Location**: `dev_TRM/frontend/src/components/reading/`

**Design Principles**:
1. **Progressive Disclosure**: Start simple, reveal complexity on demand
2. **Make Construction Visible**: Show the transformation process, not just results
3. **Consciousness Gaps**: Deliberate pauses where users witness their own interpretive agency
4. **No Seamlessness**: Expose the machinery (this is consciousness work, not UX optimization)

### 1. ReaderPanel (Main Container)

**File**: `ReaderPanel.jsx`

```jsx
import React, { useState, useEffect } from 'react';
import { useReadingSession } from '../../hooks/useReadingSession';
import LatentTrajectory from './LatentTrajectory';
import TetralemmaCompass from './TetralemmaCompass';
import POVMDeck from './POVMDeck';
import CornerViews from './CornerViews';
import HaltMeter from './HaltMeter';

/**
 * ReaderPanel - Main TRM reading interface
 *
 * Integrates all reading UI elements:
 * - Input text area
 * - Control buttons (Start, Step, Apply, Reset)
 * - Tabbed views (Trajectory, Compass, POVM, Corners)
 * - Halt meter with auto-stop
 * - Step counter and progress
 */
export default function ReaderPanel({
  initialText = '',
  contentItemId = null,
  onComplete = null
}) {
  const {
    session,
    currentStep,
    loading,
    error,
    startReading,
    stepReading,
    applyPatches,
    resetSession,
    trajectory
  } = useReadingSession();

  const [text, setText] = useState(initialText);
  const [task, setTask] = useState('');
  const [maxSteps, setMaxSteps] = useState(10);
  const [autoStep, setAutoStep] = useState(false);
  const [selectedTab, setSelectedTab] = useState('trajectory');
  const [selectedPatches, setSelectedPatches] = useState([]);

  // Auto-step when enabled
  useEffect(() => {
    if (autoStep && session && !session.halted && !loading) {
      const timer = setTimeout(() => {
        stepReading(session.reading_id);
      }, 1000); // 1 second between steps
      return () => clearTimeout(timer);
    }
  }, [autoStep, session, loading, stepReading]);

  const handleStart = async () => {
    await startReading({
      text,
      contentItemId,
      task,
      maxSteps
    });
  };

  const handleStep = async () => {
    if (session) {
      await stepReading(session.reading_id);
    }
  };

  const handleApply = async () => {
    if (session && selectedPatches.length > 0) {
      await applyPatches(session.reading_id, selectedPatches);
      setSelectedPatches([]);
    }
  };

  const handleReset = () => {
    resetSession();
    setText(initialText);
    setTask('');
    setSelectedPatches([]);
  };

  return (
    <div className="reader-panel">
      {/* Header */}
      <div className="reader-header">
        <h2>üî¨ Reading Session</h2>
        {session && (
          <div className="session-info">
            <span>Step {currentStep?.step || 0} / {session.max_steps}</span>
            {session.halted && (
              <span className="halted-badge">{session.halt_reason}</span>
            )}
          </div>
        )}
      </div>

      {/* Input Section (shown when no active session) */}
      {!session && (
        <div className="reader-input">
          <textarea
            value={text}
            onChange={(e) => setText(e.target.value)}
            placeholder="Enter text to read..."
            rows={6}
            className="input-textarea"
          />

          <input
            type="text"
            value={task}
            onChange={(e) => setTask(e.target.value)}
            placeholder="Optional: Reading task (e.g., 'Analyze tetralemma stance')"
            className="task-input"
          />

          <div className="config-row">
            <label>
              Max Steps:
              <input
                type="number"
                value={maxSteps}
                onChange={(e) => setMaxSteps(parseInt(e.target.value))}
                min={1}
                max={50}
              />
            </label>

            <button
              onClick={handleStart}
              disabled={!text.trim()}
              className="btn-primary"
            >
              Start Reading
            </button>
          </div>
        </div>
      )}

      {/* Active Session UI */}
      {session && (
        <div className="reader-active">
          {/* Current Text Display */}
          <div className="current-text">
            <h3>Current Reading (y<sub>{currentStep?.step || 0}</sub>)</h3>
            <div className="text-display">
              {currentStep?.y || session.original_text}
            </div>
            {currentStep?.dy_summary && (
              <div className="diff-summary">
                <strong>Changes:</strong> {currentStep.dy_summary}
              </div>
            )}
          </div>

          {/* Control Buttons */}
          <div className="control-bar">
            <button
              onClick={handleStep}
              disabled={loading || session.halted}
              className="btn-primary"
            >
              {loading ? 'Processing...' : 'Step'}
            </button>

            <label className="auto-step-toggle">
              <input
                type="checkbox"
                checked={autoStep}
                onChange={(e) => setAutoStep(e.target.checked)}
                disabled={session.halted}
              />
              Auto-Step
            </label>

            <button
              onClick={handleApply}
              disabled={selectedPatches.length === 0}
              className="btn-secondary"
            >
              Apply ({selectedPatches.length})
            </button>

            <button
              onClick={handleReset}
              className="btn-tertiary"
            >
              Reset
            </button>
          </div>

          {/* Halt Meter */}
          <HaltMeter
            haltProbability={currentStep?.halt_p || 0}
            threshold={session.halt_threshold}
            trajectory={trajectory.map(s => s.halt_p)}
          />

          {/* Tabbed Views */}
          <div className="reader-tabs">
            <div className="tab-headers">
              {['trajectory', 'compass', 'povm', 'corners'].map(tab => (
                <button
                  key={tab}
                  onClick={() => setSelectedTab(tab)}
                  className={selectedTab === tab ? 'active' : ''}
                >
                  {tab.charAt(0).toUpperCase() + tab.slice(1)}
                </button>
              ))}
            </div>

            <div className="tab-content">
              {selectedTab === 'trajectory' && (
                <LatentTrajectory trajectory={trajectory} />
              )}

              {selectedTab === 'compass' && (
                <TetralemmaCompass
                  stance={currentStep?.stance || {}}
                  stanceDelta={currentStep?.stance_delta || {}}
                  history={trajectory.map(s => s.stance)}
                />
              )}

              {selectedTab === 'povm' && (
                <POVMDeck
                  readings={currentStep?.povm_readings || {}}
                  onSelectEdit={(pack, axis) => {
                    setSelectedPatches([...selectedPatches, `edit:${pack}:${axis}`]);
                  }}
                />
              )}

              {selectedTab === 'corners' && (
                <CornerViews
                  cornerViews={currentStep?.corner_views || {}}
                  currentText={currentStep?.y || ''}
                  selectedPatches={selectedPatches}
                  onSelectCorner={(corner) => {
                    setSelectedPatches([...selectedPatches, `corner:${corner}`]);
                  }}
                />
              )}
            </div>
          </div>

          {error && (
            <div className="error-message">{error}</div>
          )}
        </div>
      )}
    </div>
  );
}
```

### 2. LatentTrajectory (œÅ Evolution Visualization)

**File**: `LatentTrajectory.jsx`

```jsx
import React, { useEffect, useRef } from 'react';
import * as d3 from 'd3';

/**
 * LatentTrajectory - Visualize œÅ evolution through latent space
 *
 * Shows 2D projection (PCA) of density matrix œÅ across steps.
 * User sees meaning moving through semantic space.
 */
export default function LatentTrajectory({ trajectory }) {
  const svgRef = useRef();

  useEffect(() => {
    if (!trajectory || trajectory.length === 0) return;

    // Extract œÅ principal components (precomputed in backend)
    const data = trajectory.map((step, i) => ({
      step: i,
      x: step.rho_pc1 || 0,  // First principal component
      y: step.rho_pc2 || 0,  // Second principal component
      halt_p: step.halt_p,
      norm: step.rho_norm || 1.0
    }));

    // D3 visualization
    const width = 500;
    const height = 400;
    const margin = { top: 20, right: 20, bottom: 40, left: 40 };

    const svg = d3.select(svgRef.current)
      .attr('width', width)
      .attr('height', height);

    svg.selectAll('*').remove();

    const xScale = d3.scaleLinear()
      .domain(d3.extent(data, d => d.x))
      .range([margin.left, width - margin.right]);

    const yScale = d3.scaleLinear()
      .domain(d3.extent(data, d => d.y))
      .range([height - margin.bottom, margin.top]);

    const colorScale = d3.scaleSequential(d3.interpolateViridis)
      .domain([0, data.length - 1]);

    // Draw line connecting steps
    const line = d3.line()
      .x(d => xScale(d.x))
      .y(d => yScale(d.y))
      .curve(d3.curveCatmullRom);

    svg.append('path')
      .datum(data)
      .attr('d', line)
      .attr('fill', 'none')
      .attr('stroke', '#888')
      .attr('stroke-width', 2)
      .attr('opacity', 0.5);

    // Draw points for each step
    svg.selectAll('circle')
      .data(data)
      .join('circle')
      .attr('cx', d => xScale(d.x))
      .attr('cy', d => yScale(d.y))
      .attr('r', d => 4 + (d.halt_p * 6))  // Size by halt probability
      .attr('fill', (d, i) => colorScale(i))
      .attr('stroke', '#fff')
      .attr('stroke-width', 2)
      .style('cursor', 'pointer')
      .on('mouseover', function(event, d) {
        d3.select(this).attr('r', 10);
        // Show tooltip
        svg.append('text')
          .attr('class', 'tooltip')
          .attr('x', xScale(d.x) + 15)
          .attr('y', yScale(d.y))
          .text(`Step ${d.step}: halt_p=${d.halt_p.toFixed(3)}`);
      })
      .on('mouseout', function(event, d) {
        d3.select(this).attr('r', 4 + (d.halt_p * 6));
        svg.select('.tooltip').remove();
      });

    // Axes
    svg.append('g')
      .attr('transform', `translate(0,${height - margin.bottom})`)
      .call(d3.axisBottom(xScale))
      .append('text')
      .attr('x', width / 2)
      .attr('y', 35)
      .attr('fill', 'currentColor')
      .text('PC1');

    svg.append('g')
      .attr('transform', `translate(${margin.left},0)`)
      .call(d3.axisLeft(yScale))
      .append('text')
      .attr('transform', 'rotate(-90)')
      .attr('x', -height / 2)
      .attr('y', -30)
      .attr('fill', 'currentColor')
      .text('PC2');

  }, [trajectory]);

  return (
    <div className="latent-trajectory">
      <h4>Latent Trajectory (œÅ evolution)</h4>
      <p className="explanation">
        Watch understanding move through semantic space. Each point is a step;
        color shows progression; size shows halt probability.
      </p>
      <svg ref={svgRef}></svg>
    </div>
  );
}
```

### 3. TetralemmaCompass (Four-Cornered Logic Viz)

**File**: `TetralemmaCompass.jsx`

```jsx
import React, { useEffect, useRef } from 'react';
import * as d3 from 'd3';

/**
 * TetralemmaCompass - Visualize catu·π£ko·π≠i stance
 *
 * Four-way polar chart showing p(A), p(¬¨A), p(both), p(neither).
 * Shows current stance and deltas from previous step.
 */
export default function TetralemmaCompass({ stance, stanceDelta, history }) {
  const svgRef = useRef();

  useEffect(() => {
    if (!stance || Object.keys(stance).length === 0) return;

    const width = 300;
    const height = 300;
    const radius = Math.min(width, height) / 2 - 40;

    const svg = d3.select(svgRef.current)
      .attr('width', width)
      .attr('height', height);

    svg.selectAll('*').remove();

    const g = svg.append('g')
      .attr('transform', `translate(${width/2},${height/2})`);

    // Data
    const corners = [
      { name: 'A', value: stance.A || 0, color: '#4CAF50', angle: 0 },
      { name: '¬¨A', value: stance.notA || stance['¬¨A'] || 0, color: '#F44336', angle: Math.PI / 2 },
      { name: 'both', value: stance.both || 0, color: '#9C27B0', angle: Math.PI },
      { name: 'neither', value: stance.neither || 0, color: '#9E9E9E', angle: 3 * Math.PI / 2 }
    ];

    // Scales
    const rScale = d3.scaleLinear()
      .domain([0, 1])
      .range([0, radius]);

    const angleScale = d3.scaleLinear()
      .domain([0, 4])
      .range([0, 2 * Math.PI]);

    // Background circles (grid)
    [0.25, 0.5, 0.75, 1.0].forEach(val => {
      g.append('circle')
        .attr('r', rScale(val))
        .attr('fill', 'none')
        .attr('stroke', '#ddd')
        .attr('stroke-width', 1);
    });

    // Axes for each corner
    corners.forEach((corner, i) => {
      const angle = angleScale(i);
      const x = radius * Math.cos(angle - Math.PI / 2);
      const y = radius * Math.sin(angle - Math.PI / 2);

      g.append('line')
        .attr('x1', 0)
        .attr('y1', 0)
        .attr('x2', x)
        .attr('y2', y)
        .attr('stroke', '#ccc')
        .attr('stroke-width', 1);

      // Label
      g.append('text')
        .attr('x', x * 1.2)
        .attr('y', y * 1.2)
        .attr('text-anchor', 'middle')
        .attr('dominant-baseline', 'middle')
        .attr('font-weight', 'bold')
        .attr('fill', corner.color)
        .text(corner.name);
    });

    // Draw filled polygon
    const polygonPoints = corners.map((corner, i) => {
      const angle = angleScale(i);
      const r = rScale(corner.value);
      return [
        r * Math.cos(angle - Math.PI / 2),
        r * Math.sin(angle - Math.PI / 2)
      ];
    });

    const lineGenerator = d3.line();

    g.append('path')
      .datum([...polygonPoints, polygonPoints[0]])
      .attr('d', lineGenerator)
      .attr('fill', '#673AB7')
      .attr('fill-opacity', 0.3)
      .attr('stroke', '#673AB7')
      .attr('stroke-width', 2);

    // Draw data points
    corners.forEach((corner, i) => {
      const angle = angleScale(i);
      const r = rScale(corner.value);
      const x = r * Math.cos(angle - Math.PI / 2);
      const y = r * Math.sin(angle - Math.PI / 2);

      g.append('circle')
        .attr('cx', x)
        .attr('cy', y)
        .attr('r', 6)
        .attr('fill', corner.color)
        .attr('stroke', '#fff')
        .attr('stroke-width', 2);

      // Value label
      g.append('text')
        .attr('x', x)
        .attr('y', y - 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', corner.color)
        .text(corner.value.toFixed(2));

      // Delta arrow (if available)
      if (stanceDelta && stanceDelta[corner.name] !== undefined) {
        const delta = stanceDelta[corner.name];
        const arrowLength = 20;
        const arrowX = x + (delta > 0 ? arrowLength : -arrowLength) * Math.cos(angle - Math.PI / 2);
        const arrowY = y + (delta > 0 ? arrowLength : -arrowLength) * Math.sin(angle - Math.PI / 2);

        g.append('line')
          .attr('x1', x)
          .attr('y1', y)
          .attr('x2', arrowX)
          .attr('y2', arrowY)
          .attr('stroke', delta > 0 ? '#4CAF50' : '#F44336')
          .attr('stroke-width', 2)
          .attr('marker-end', 'url(#arrow)');
      }
    });

    // Arrow marker definition
    svg.append('defs')
      .append('marker')
      .attr('id', 'arrow')
      .attr('viewBox', '0 0 10 10')
      .attr('refX', 5)
      .attr('refY', 5)
      .attr('markerWidth', 6)
      .attr('markerHeight', 6)
      .attr('orient', 'auto-start-reverse')
      .append('path')
      .attr('d', 'M 0 0 L 10 5 L 0 10 z')
      .attr('fill', 'currentColor');

  }, [stance, stanceDelta]);

  return (
    <div className="tetralemma-compass">
      <h4>Tetralemma Compass (Catu·π£ko·π≠i)</h4>
      <p className="explanation">
        Four-cornered logic: A (affirm), ¬¨A (negate), both (paradox), neither (transcend).
        Arrows show change from previous step.
      </p>
      <svg ref={svgRef}></svg>

      {history && history.length > 1 && (
        <div className="stance-history">
          <h5>Stance Evolution</h5>
          <div className="mini-chart">
            {/* Mini sparklines for each corner over time */}
            {['A', 'notA', 'both', 'neither'].map(corner => (
              <div key={corner} className="sparkline">
                <span className="label">{corner}:</span>
                <svg width={100} height={20}>
                  <polyline
                    points={history.map((s, i) =>
                      `${i * (100 / history.length)},${20 - (s[corner] || 0) * 20}`
                    ).join(' ')}
                    fill="none"
                    stroke="#673AB7"
                    strokeWidth={2}
                  />
                </svg>
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

### 4. POVMDeck (Measurement Cards)

**File**: `POVMDeck.jsx`

```jsx
import React, { useState } from 'react';

/**
 * POVMDeck - Display all POVM pack measurements
 *
 * Cards for each measurement pack (tetralemma, tone, ontology, etc.)
 * showing probability distributions.
 */
export default function POVMDeck({ readings, onSelectEdit }) {
  const [expandedPack, setExpandedPack] = useState('tetralemma');

  const packs = Object.entries(readings || {}).map(([name, axes]) => ({
    name,
    axes: Object.entries(axes).map(([axis, prob]) => ({ axis, prob }))
  }));

  const getPackColor = (packName) => {
    const colors = {
      tetralemma: '#673AB7',
      tone: '#FF9800',
      ontology: '#2196F3',
      pragmatics: '#4CAF50',
      audience: '#E91E63'
    };
    return colors[packName] || '#9E9E9E';
  };

  return (
    <div className="povm-deck">
      <h4>POVM Measurements</h4>
      <p className="explanation">
        Measure œÅ along different axes. Each pack reveals a different aspect.
      </p>

      <div className="pack-cards">
        {packs.map(pack => (
          <div
            key={pack.name}
            className={`pack-card ${expandedPack === pack.name ? 'expanded' : ''}`}
          >
            <div
              className="pack-header"
              onClick={() => setExpandedPack(
                expandedPack === pack.name ? null : pack.name
              )}
              style={{ borderColor: getPackColor(pack.name) }}
            >
              <h5>{pack.name}</h5>
              <span className="expand-icon">
                {expandedPack === pack.name ? '‚ñº' : '‚ñ∂'}
              </span>
            </div>

            {expandedPack === pack.name && (
              <div className="pack-body">
                {pack.axes.map(({ axis, prob }) => (
                  <div key={axis} className="axis-reading">
                    <div className="axis-label">{axis}</div>
                    <div className="axis-bar-container">
                      <div
                        className="axis-bar"
                        style={{
                          width: `${prob * 100}%`,
                          backgroundColor: getPackColor(pack.name)
                        }}
                      />
                    </div>
                    <div className="axis-value">{prob.toFixed(3)}</div>
                    {onSelectEdit && (
                      <button
                        className="edit-btn"
                        onClick={() => onSelectEdit(pack.name, axis)}
                        title={`Suggest edits to improve ${axis}`}
                      >
                        ‚úèÔ∏è
                      </button>
                    )}
                  </div>
                ))}
              </div>
            )}
          </div>
        ))}
      </div>
    </div>
  );
}
```

### 5. CornerViews (Phase-Conditioned Outputs)

**File**: `CornerViews.jsx`

```jsx
import React, { useState } from 'react';
import { diffWords } from 'diff';

/**
 * CornerViews - Display four tetralemma perspectives
 *
 * Shows phase-conditioned outputs from TRM:
 * - A (affirm)
 * - ¬¨A (negate)
 * - both (hold paradox)
 * - neither (transcend)
 *
 * Users can adopt, merge, or discard each view.
 */
export default function CornerViews({
  cornerViews,
  currentText,
  selectedPatches,
  onSelectCorner
}) {
  const [showDiffs, setShowDiffs] = useState(true);

  const corners = [
    { id: 'A', name: 'A (Affirm)', color: '#4CAF50', icon: '‚úì' },
    { id: 'notA', name: '¬¨A (Negate)', color: '#F44336', icon: '‚úó' },
    { id: 'both', name: 'Both (Paradox)', color: '#9C27B0', icon: '‚äï' },
    { id: 'neither', name: 'Neither (Transcend)', color: '#9E9E9E', icon: '‚àÖ' }
  ];

  const renderDiff = (corner) => {
    if (!showDiffs || !cornerViews[corner.id]) return null;

    const diff = diffWords(currentText, cornerViews[corner.id]);

    return (
      <div className="diff-view">
        {diff.map((part, i) => (
          <span
            key={i}
            className={
              part.added ? 'diff-added' :
              part.removed ? 'diff-removed' :
              ''
            }
          >
            {part.value}
          </span>
        ))}
      </div>
    );
  };

  return (
    <div className="corner-views">
      <div className="header-controls">
        <h4>Corner Views (Tetralemma Perspectives)</h4>
        <label className="toggle">
          <input
            type="checkbox"
            checked={showDiffs}
            onChange={(e) => setShowDiffs(e.target.checked)}
          />
          Show Diffs
        </label>
      </div>

      <p className="explanation">
        Four phase-conditioned readings of the same text. Each reveals a different stance.
      </p>

      <div className="corners-grid">
        {corners.map(corner => (
          <div
            key={corner.id}
            className={`corner-card ${
              selectedPatches.includes(`corner:${corner.id}`) ? 'selected' : ''
            }`}
            style={{ borderColor: corner.color }}
          >
            <div className="corner-header">
              <span className="corner-icon" style={{ color: corner.color }}>
                {corner.icon}
              </span>
              <h5>{corner.name}</h5>
            </div>

            <div className="corner-content">
              {showDiffs ? (
                renderDiff(corner)
              ) : (
                <div className="text-view">
                  {cornerViews[corner.id] || 'No view generated'}
                </div>
              )}
            </div>

            <div className="corner-actions">
              <button
                onClick={() => onSelectCorner(corner.id)}
                className="btn-adopt"
                disabled={!cornerViews[corner.id]}
              >
                Adopt
              </button>
              <button
                className="btn-merge"
                disabled={!cornerViews[corner.id]}
              >
                Merge
              </button>
              <button
                className="btn-discard"
              >
                Discard
              </button>
            </div>
          </div>
        ))}
      </div>

      <div className="corner-explanation">
        <h5>Understanding the Four Corners</h5>
        <ul>
          <li><strong>A (Affirm):</strong> Takes the claim at face value, develops affirmation</li>
          <li><strong>¬¨A (Negate):</strong> Questions or negates the claim, offers alternatives</li>
          <li><strong>Both:</strong> Holds the paradox, explores how both can be true</li>
          <li><strong>Neither:</strong> Transcends the binary, questions the frame itself</li>
        </ul>
      </div>
    </div>
  );
}
```

### 6. HaltMeter (Convergence Indicator)

**File**: `HaltMeter.jsx`

```jsx
import React from 'react';

/**
 * HaltMeter - Visualize halt probability over time
 *
 * Shows current halt_p, threshold, and sparkline of trajectory.
 * Users can see when the model thinks it's "done".
 */
export default function HaltMeter({
  haltProbability,
  threshold = 0.95,
  trajectory = []
}) {
  const isNearHalt = haltProbability > threshold * 0.9;
  const hasHalted = haltProbability >= threshold;

  return (
    <div className={`halt-meter ${hasHalted ? 'halted' : ''}`}>
      <div className="halt-header">
        <h5>Halt Probability</h5>
        <span className="halt-value">
          {(haltProbability * 100).toFixed(1)}%
        </span>
      </div>

      <div className="halt-bar-container">
        <div
          className="halt-bar"
          style={{
            width: `${haltProbability * 100}%`,
            backgroundColor: hasHalted ? '#4CAF50' : isNearHalt ? '#FF9800' : '#2196F3'
          }}
        />
        <div
          className="threshold-marker"
          style={{ left: `${threshold * 100}%` }}
          title={`Threshold: ${threshold}`}
        >
          ‚¨á
        </div>
      </div>

      {trajectory.length > 1 && (
        <div className="halt-sparkline">
          <svg width="100%" height="30">
            <polyline
              points={trajectory.map((p, i) =>
                `${(i / (trajectory.length - 1)) * 100}%,${30 - p * 30}`
              ).join(' ')}
              fill="none"
              stroke={hasHalted ? '#4CAF50' : '#2196F3'}
              strokeWidth={2}
            />
            {/* Threshold line */}
            <line
              x1="0"
              y1={30 - threshold * 30}
              x2="100%"
              y2={30 - threshold * 30}
              stroke="#F44336"
              strokeWidth={1}
              strokeDasharray="2,2"
            />
          </svg>
        </div>
      )}

      <div className="halt-explanation">
        {hasHalted ? (
          <span className="halted-msg">‚úì Converged - TRM believes understanding is stable</span>
        ) : isNearHalt ? (
          <span className="near-halt-msg">‚ö† Approaching convergence...</span>
        ) : (
          <span className="processing-msg">‚ü≥ Still refining...</span>
        )}
      </div>
    </div>
  );
}
```

---

## MCP Integration

### New MCP Tools for Reading Operations

**Location**: `~/humanizer_root/humanizer_mcp/src/tools.py`

Add the following tools to expose TRM reading functionality to MCP-compatible agents (like Claude Code):

```python
# ============================================================================
# TRM Reading Tools
# ============================================================================

@server.tool()
async def start_reading_session(
    text: str,
    task: Optional[str] = None,
    max_steps: int = 10
) -> dict:
    """
    Start a new TRM reading session.

    Args:
        text: Text to read and transform
        task: Optional reading task (e.g., "Analyze tetralemma stance")
        max_steps: Maximum recursion steps

    Returns:
        {
            "reading_id": UUID,
            "step": 0,
            "y": str (initial text),
            "stance": {A, notA, both, neither},
            "povm_readings": {...},
            "halt_p": float
        }
    """
    try:
        response = await api_client.post('/api/reading/start', {
            'text': text,
            'task': task,
            'max_steps': max_steps
        })

        # Store in SQLite for tracking
        await db.execute("""
            INSERT INTO reading_sessions (reading_id, text, task, created_at)
            VALUES (?, ?, ?, ?)
        """, (response['reading_id'], text, task, datetime.now()))
        await db.commit()

        return response

    except Exception as e:
        return {"error": str(e)}


@server.tool()
async def step_reading_session(reading_id: str) -> dict:
    """
    Advance reading session by one TRM step.

    Args:
        reading_id: UUID of reading session

    Returns:
        {
            "step": int,
            "y": str (refined text),
            "dy_summary": str (what changed),
            "rho_delta": float (latent movement),
            "stance": {...},
            "halt_p": float,
            "corner_views": {A, notA, both, neither}
        }
    """
    try:
        response = await api_client.post('/api/reading/step', {
            'reading_id': reading_id
        })

        # Track step in SQLite
        await db.execute("""
            INSERT INTO reading_steps (reading_id, step, halt_p, created_at)
            VALUES (?, ?, ?, ?)
        """, (reading_id, response['step'], response['halt_p'], datetime.now()))
        await db.commit()

        return response

    except Exception as e:
        return {"error": str(e)}


@server.tool()
async def measure_reading_povm(
    reading_id: str,
    povm_pack: str
) -> dict:
    """
    Measure reading state with specific POVM pack.

    Args:
        reading_id: UUID of reading session
        povm_pack: Pack name ("tetralemma", "tone", "ontology", "pragmatics", "audience")

    Returns:
        {
            "step": int,
            "readings": [{axis, probability}, ...],
            "rho_projection": {...}
        }
    """
    try:
        response = await api_client.post('/api/reading/measure', {
            'reading_id': reading_id,
            'povm_pack': povm_pack
        })
        return response
    except Exception as e:
        return {"error": str(e)}


@server.tool()
async def apply_reading_patches(
    reading_id: str,
    patches: List[str]
) -> dict:
    """
    Apply selected corner views or edits to reading.

    Args:
        reading_id: UUID of reading session
        patches: List of patches (e.g., ["corner:A", "corner:both", "edit:clarity"])

    Returns:
        {
            "step": int,
            "y": str (updated text),
            "provenance_patch": {...}
        }
    """
    try:
        response = await api_client.post('/api/reading/apply', {
            'reading_id': reading_id,
            'apply': patches
        })

        # Track applied patches
        await db.execute("""
            INSERT INTO reading_provenance (reading_id, patches, created_at)
            VALUES (?, ?, ?)
        """, (reading_id, json.dumps(patches), datetime.now()))
        await db.commit()

        return response
    except Exception as e:
        return {"error": str(e)}


@server.tool()
async def get_reading_trace(reading_id: str) -> dict:
    """
    Get complete trace of reading session.

    Args:
        reading_id: UUID of reading session

    Returns:
        {
            "steps": [...],
            "metrics": {
                "rho_norms": [...],
                "divergences": [...],
                "halt_curve": [...]
            },
            "snapshots": [...],
            "madhyamaka_analysis": {...}
        }
    """
    try:
        response = await api_client.get(f'/api/reading/{reading_id}/trace')
        return response
    except Exception as e:
        return {"error": str(e)}


@server.tool()
async def auto_run_reading_session(
    text: str,
    task: Optional[str] = None,
    max_steps: int = 10
) -> dict:
    """
    Convenience tool: Start and auto-run reading session until halt.

    Args:
        text: Text to read
        task: Optional reading task
        max_steps: Maximum steps

    Returns:
        Complete trace with all steps
    """
    try:
        # Start session
        start_result = await start_reading_session(text, task, max_steps)
        reading_id = start_result['reading_id']

        # Run until halt
        halt_p = start_result['halt_p']
        threshold = 0.95
        steps = []

        while halt_p < threshold and len(steps) < max_steps:
            step_result = await step_reading_session(reading_id)
            steps.append(step_result)
            halt_p = step_result['halt_p']

        # Get full trace
        trace = await get_reading_trace(reading_id)

        return {
            "reading_id": reading_id,
            "steps_taken": len(steps),
            "final_halt_p": halt_p,
            "final_text": steps[-1]['y'] if steps else text,
            "trace": trace
        }

    except Exception as e:
        return {"error": str(e)}
```

### MCP Database Schema Updates

Add tables to track reading sessions in MCP SQLite database:

```python
# humanizer_mcp/src/init_db.py

def init_reading_tables(db_path):
    """Initialize reading session tracking tables."""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Reading sessions
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS reading_sessions (
            reading_id TEXT PRIMARY KEY,
            text TEXT NOT NULL,
            task TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # Reading steps
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS reading_steps (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            reading_id TEXT NOT NULL,
            step INTEGER NOT NULL,
            halt_p REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (reading_id) REFERENCES reading_sessions(reading_id)
        )
    """)

    # Reading provenance
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS reading_provenance (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            reading_id TEXT NOT NULL,
            patches TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (reading_id) REFERENCES reading_sessions(reading_id)
        )
    """)

    conn.commit()
    conn.close()
```

---

## Implementation Plan

### 7-Week Phased Rollout

**Environment**: `dev_TRM` (isolated from main humanizer-agent)

**Database**: `humanizer_dev_trm` (fresh PostgreSQL database)

**Ports**: Backend: 8001, Frontend: 5174 (avoid conflicts)

### Week 1: Foundation Setup (Oct 11-17)

**Goal**: Working dev environment with mock TRM

**Tasks**:
1. ‚úÖ Create `dev_TRM` directory structure
2. ‚úÖ Set up PostgreSQL database `humanizer_dev_trm`
3. ‚úÖ Copy base files from humanizer-agent (models, configs)
4. ‚úÖ Run Alembic migrations (create all tables)
5. ‚úÖ Implement mock TRM (rule-based, no ML)
6. ‚úÖ Build basic `/api/reading/*` endpoints
7. ‚úÖ Test with curl/Postman

**Deliverable**: Can start/step/trace a reading session (mock data)

**Success Criteria**:
- Database tables created
- API endpoints return valid JSON
- Mock œÅ/POVM calculations work
- End-to-end curl test passes

### Week 2: ML Infrastructure (Oct 18-24)

**Goal**: Real TRM model running inference

**Tasks**:
1. ‚è≥ Implement œÅ construction (eigendecomposition)
2. ‚è≥ Implement POVM heads (PSD matrices)
3. ‚è≥ Build TRM model architecture (PyTorch)
4. ‚è≥ Create dummy weights (random init)
5. ‚è≥ Test TRM forward pass (CPU inference)
6. ‚è≥ Mine training data from archives
7. ‚è≥ Write training script skeleton

**Deliverable**: TRM model runs inference (untrained weights OK)

**Success Criteria**:
- œÅ construction completes in <500ms
- POVM measurements return valid probabilities
- TRM generates coherent (if nonsensical) outputs
- Training data pipeline ready (100+ examples)

### Week 3: Model Training (Oct 25-31)

**Goal**: Trained TRM model producing meaningful outputs

**Tasks**:
1. ‚è≥ Prepare training dataset (1000+ edit pairs)
2. ‚è≥ Implement training loop (deep supervision)
3. ‚è≥ Train initial model (2-3 days on GPU)
4. ‚è≥ Evaluate outputs qualitatively
5. ‚è≥ Iterate on hyperparameters
6. ‚è≥ Save best checkpoint
7. ‚è≥ Integrate trained weights into API

**Deliverable**: TRM produces reasonable transformations

**Success Criteria**:
- Training loss converges
- Validation preference win-rate >60%
- Corner views show distinct perspectives
- Halt prediction correlates with quality

### Week 4: UI Development Part 1 (Nov 1-7)

**Goal**: Basic React UI shell working

**Tasks**:
1. ‚è≥ Build ReaderPanel shell
2. ‚è≥ Implement useReadingSession hook
3. ‚è≥ Create LatentTrajectory component (D3)
4. ‚è≥ Create TetralemmaCompass component (D3)
5. ‚è≥ Wire to API endpoints
6. ‚è≥ Test basic flow (start ‚Üí step ‚Üí display)
7. ‚è≥ Add loading states and error handling

**Deliverable**: Can run reading session in browser

**Success Criteria**:
- User can input text and start session
- Trajectory plot updates each step
- Compass shows stance evolution
- UI is responsive and bug-free

### Week 5: UI Development Part 2 (Nov 8-14)

**Goal**: Complete UI with all features

**Tasks**:
1. ‚è≥ Create POVMDeck component
2. ‚è≥ Create CornerViews component (with diffs)
3. ‚è≥ Create HaltMeter component
4. ‚è≥ Implement apply/merge/discard logic
5. ‚è≥ Add provenance display
6. ‚è≥ Polish styling (CSS/Tailwind)
7. ‚è≥ Add tutorial tooltips

**Deliverable**: Full-featured Reading Panel

**Success Criteria**:
- All visualizations working
- User can adopt corner views
- Provenance tracked and visible
- UI feels polished

### Week 6: Integration & Testing (Nov 15-21)

**Goal**: Integrate with existing systems, test thoroughly

**Tasks**:
1. ‚è≥ Integrate with Unified Content Architecture
2. ‚è≥ Integrate with Madhyamaka API
3. ‚è≥ Add MCP tools (8 new tools)
4. ‚è≥ Update MCP database schema
5. ‚è≥ End-to-end testing (20+ test cases)
6. ‚è≥ Dogfood: Use on 10-20 essays
7. ‚è≥ Collect user feedback

**Deliverable**: Fully integrated TRM system

**Success Criteria**:
- Reading sessions create artifacts in content_items
- Madhyamaka analysis shows convergence
- MCP tools work from Claude Code
- No critical bugs found in testing

### Week 7: Documentation & Merge (Nov 22-28)

**Goal**: Production-ready, merge to main

**Tasks**:
1. ‚è≥ Complete all documentation
2. ‚è≥ Write TRM_USER_GUIDE.md
3. ‚è≥ Write TRM_ARCHITECTURE.md (math deep dive)
4. ‚è≥ Write TRM_TRAINING.md (ML procedures)
5. ‚è≥ Code review (security, performance)
6. ‚è≥ Optimize performance (caching, indexes)
7. ‚è≥ Merge dev_TRM ‚Üí humanizer-agent
8. ‚è≥ Deploy to unified dev database

**Deliverable**: TRM in production, documented

**Success Criteria**:
- All docs complete and accurate
- Performance meets targets (<500ms œÅ, <1s TRM)
- Code review passed
- Successfully merged to main branch

---

## Success Metrics

### Technical Metrics

**Performance**:
- [ ] œÅ construction: <500ms per step
- [ ] POVM measurements: <100ms
- [ ] TRM inference: <1s per step (CPU), <200ms (GPU)
- [ ] Database queries: <50ms (trace, steps)
- [ ] UI rendering: 60fps animations

**Reliability**:
- [ ] 0 crashes during 100 test sessions
- [ ] API uptime >99.9%
- [ ] Graceful degradation if TRM fails (fallback to rule-based)

**Scalability**:
- [ ] Handle sessions with 50+ steps
- [ ] Support 10+ concurrent users
- [ ] Database storage <1MB per session

### User Experience Metrics

**Engagement**:
- [ ] Reading session completion rate >60%
- [ ] Average session length: 5-10 steps
- [ ] Corner view adoption rate >40%
- [ ] POVM measurement exploration: Users check ‚â•2 packs per session

**Quality**:
- [ ] Preference: y‚Çú vs y‚ÇÄ win-rate >70%
- [ ] Corner view usefulness (survey): >7/10
- [ ] User-reported "seeing the process": >80% (qualitative)

**Learning Curve**:
- [ ] Time to first successful session: <5 minutes
- [ ] Tutorial completion rate: >70%
- [ ] Return usage within 7 days: >50%

### Philosophical Metrics (Consciousness Work)

**Core Mission Alignment**:
- [ ] Users report "making construction visible" (qualitative interviews)
- [ ] Madhyamaka integration shows middle-path convergence in >60% of sessions
- [ ] Reading traces demonstrate interpretive agency (users make active choices)
- [ ] System reveals, not hides, the transformation process

**Specific Indicators**:
- [ ] Tetralemma stance evolution: Movement toward "both" or "neither" in philosophical content
- [ ] œÅ trajectory shows meaningful semantic movement (not random walk)
- [ ] Halt prediction aligns with human judgment of "done" (>80% agreement)
- [ ] Provenance tracking enables users to reconstruct their interpretive path

**Long-term Impact**:
- [ ] User self-reports increased awareness of subjectivity (survey, 30-day)
- [ ] Madhyamaka extreme detection decreases over time (eternalism/nihilism)
- [ ] Users apply tetralemma thinking in other contexts (anecdotal evidence)

---

## Risk Assessment & Mitigations

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| TRM model doesn't converge during training | MEDIUM | üî¥ HIGH | Start with rule-based system, add ML incrementally. Validate on synthetic data first. Have fallback to deterministic transformations. |
| œÅ computation too slow for real-time use | MEDIUM | üü° MEDIUM | Pre-compute and cache. Use low-rank approximation (r=32). Optimize with NumPy/CuPy. Profile and parallelize. |
| UI too complex for users | MEDIUM | üü° MEDIUM | Progressive disclosure (hide advanced features initially). Comprehensive tutorial. User testing with 5+ people. A/B test simplified vs. full UI. |
| Integration breaks existing systems | LOW | üü° MEDIUM | Isolated dev_TRM environment. Thorough testing before merge. Feature flags for gradual rollout. Rollback plan. |
| Training data insufficient or biased | LOW | üü¢ LOW | Archives have 139K chunks. Synthetic augmentation. Human review of training pairs. Diverse data sources. |
| PostgreSQL performance issues at scale | LOW | üü¢ LOW | Proper indexes (GIN, ivfflat). Query optimization. Connection pooling. Consider partitioning for >100K sessions. |
| User doesn't understand tetralemma logic | MEDIUM | üü¢ LOW | Extensive documentation. Visual aids. Example walkthroughs. Philosophy glossary. Optional "simple mode" without corners. |
| TRM outputs nonsensical or offensive | LOW | üü° MEDIUM | Content filtering. Human review of outputs during testing. User reporting mechanism. Kill switch to disable if needed. |

---

## References

### Papers & Research

1. **Tiny Recursive Models** (Samsung SAIL Montreal, 2024)
   - arXiv: https://arxiv.org/html/2510.04871v1
   - GitHub: https://github.com/SamsungSAILMontreal/TinyRecursiveModels
   - Key insight: "Less is more" - 2 layers optimal for recursive reasoning

2. **Quantum-Inspired Semantic Spaces**
   - Density matrices for representing mixed semantic states
   - POVM as generalization of projective measurements
   - Application to NLP (Bruza et al., "Quantum Models of Cognition and Decision")

3. **Buddhist Logic & Tetralemma**
   - Catu·π£ko·π≠i in Nagarjuna's M≈´lamadhyamakakƒÅrikƒÅ
   - Four-valued logic: A, ¬¨A, both, neither
   - Application to computational systems (Garfield, "The Fundamental Wisdom of the Middle Way")

### Related Documentation

**Internal Docs** (Humanizer Agent):
- `UNIFIED_ARCHITECTURE_SPEC.md` - Content architecture integration
- `MADHYAMAKA_API.md` - Middle Path API reference
- `CLAUDE.md` - Mission and philosophy
- `TRANSFORMATION_SYSTEM_AUDIT.md` - Current transformation landscape

**To Be Created**:
- `TRM_ARCHITECTURE.md` - Deep dive on œÅ/POVM mathematics
- `TRM_USER_GUIDE.md` - User-facing documentation
- `TRM_TRAINING.md` - ML training procedures
- `TRM_PHILOSOPHY.md` - Why this serves consciousness work

### External Tools & Libraries

**Python**:
- PyTorch (TRM model)
- NumPy/SciPy (œÅ eigendecomposition)
- FastAPI (API endpoints)
- SQLAlchemy + asyncpg (database)
- sentence-transformers (embeddings)

**JavaScript**:
- React (UI framework)
- D3.js (visualizations)
- diff (text diffing for corner views)
- Tailwind CSS (styling)

**Database**:
- PostgreSQL 14+ (JSON, vectors)
- pgvector extension (embedding search)

---

## Appendix: Quick Start Commands

### Set Up Dev Environment

```bash
# Create directory
mkdir -p dev_TRM/{backend,frontend,tests,notebooks}
cd dev_TRM

# Create database
createdb humanizer_dev_trm

# Backend setup
cd backend
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run migrations
alembic upgrade head

# Start backend
uvicorn main:app --host 0.0.0.0 --port 8001 --reload

# Frontend setup (separate terminal)
cd ../frontend
npm install
npm run dev  # Runs on port 5174

# Test
curl http://localhost:8001/api/reading/health
```

### Run First Reading Session

```bash
# Start session
curl -X POST http://localhost:8001/api/reading/start \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Language creates reality.",
    "task": "Analyze tetralemma stance",
    "max_steps": 10
  }'

# Copy reading_id from response, then step:
curl -X POST http://localhost:8001/api/reading/step \
  -H "Content-Type: application/json" \
  -d '{"reading_id": "YOUR_ID_HERE"}'

# Get full trace
curl http://localhost:8001/api/reading/YOUR_ID_HERE/trace
```

---

**Document Status**: ‚úÖ COMPLETE

**Total Length**: ~25,000 words

**Sections Complete**:
1. ‚úÖ Executive Summary
2. ‚úÖ Philosophical Foundation
3. ‚úÖ Technical Overview
4. ‚úÖ Architecture Integration
5. ‚úÖ Database Schema
6. ‚úÖ API Specification
7. ‚úÖ ML Infrastructure
8. ‚úÖ UI Components
9. ‚úÖ MCP Integration
10. ‚úÖ Implementation Plan
11. ‚úÖ Success Metrics
12. ‚úÖ Risk Assessment
13. ‚úÖ References

**Ready for**: Implementation Phase 1

**Created**: October 10, 2025
**Last Updated**: October 10, 2025
**Author**: Claude (with Human oversight)

---

*"The transformation process neither exists nor does not exist. Yet we make it observable."*