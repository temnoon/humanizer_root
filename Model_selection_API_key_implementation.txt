      Implementation Plan: Allegorical Transform Enhancements                                                     
                                                                                                                  
      Overview                                                                                                    
                                                                                                                  
      Add length control and LLM model selection (Cloudflare + external APIs) to Allegorical Transform, with      
      secure API key storage restricted to PRO+ tiers.                                                            
                                                                                                                  
      ---                                                                                                         
      Phase 1: Database Migration & Security Infrastructure                                                       
                                                                                                                  
      1.1 Create New Migration: 0008_api_keys_and_model_preferences.sql                                           
                                                                                                                  
      -- Add API key storage (encrypted)                                                                          
      ALTER TABLE users ADD COLUMN openai_api_key_encrypted TEXT;                                                 
      ALTER TABLE users ADD COLUMN anthropic_api_key_encrypted TEXT;                                              
      ALTER TABLE users ADD COLUMN google_api_key_encrypted TEXT;                                                 
                                                                                                                  
      -- Add model preferences                                                                                    
      ALTER TABLE users ADD COLUMN preferred_model TEXT DEFAULT '@cf/meta/llama-3.1-8b-instruct';                 
      ALTER TABLE users ADD COLUMN preferred_length TEXT DEFAULT 'same'                                           
        CHECK(preferred_length IN ('shorter', 'same', 'longer', 'much_longer'));                                  
                                                                                                                  
      -- Track when keys were last updated (for audit)                                                            
      ALTER TABLE users ADD COLUMN api_keys_updated_at INTEGER;                                                   
                                                                                                                  
      1.2 Implement Encryption Utility (src/utils/encryption.ts)                                                  
                                                                                                                  
      // AES-GCM encryption using Web Crypto API                                                                  
      // Key derivation: SHA-256(JWT_SECRET + user_id)                                                            
                                                                                                                  
      export async function encryptAPIKey(                                                                        
        apiKey: string,                                                                                           
        userId: string,                                                                                           
        jwtSecret: string                                                                                         
      ): Promise<string> {                                                                                        
        // Derive encryption key from JWT_SECRET + user ID                                                        
        // Return: base64(iv):base64(encrypted_data)                                                              
      }                                                                                                           
                                                                                                                  
      export async function decryptAPIKey(                                                                        
        encrypted: string,                                                                                        
        userId: string,                                                                                           
        jwtSecret: string                                                                                         
      ): Promise<string> {                                                                                        
        // Reverse of encryption                                                                                  
        // Throws error if decryption fails                                                                       
      }                                                                                                           
                                                                                                                  
      Security Properties:                                                                                        
      - âœ… Each user has unique encryption key (JWT_SECRET + user_id)                                              
      - âœ… Keys persist across password changes                                                                    
      - âœ… Cannot be decrypted without JWT_SECRET (Cloudflare-only secret)                                         
      - âœ… IV (initialization vector) randomized per encryption                                                    
                                                                                                                  
      ---                                                                                                         
      Phase 2: Backend API Changes                                                                                
                                                                                                                  
      2.1 New Endpoint: POST /api/user/api-keys                                                                   
                                                                                                                  
      Purpose: Set/update external API keys (PRO+ only)                                                           
                                                                                                                  
      interface SetAPIKeysRequest {                                                                               
        openai_api_key?: string;                                                                                  
        anthropic_api_key?: string;                                                                               
        google_api_key?: string;                                                                                  
      }                                                                                                           
                                                                                                                  
      // Validates tier (PRO/PREMIUM/ADMIN only)                                                                  
      // Encrypts keys before storage                                                                             
      // Returns success/error                                                                                    
                                                                                                                  
      2.2 New Endpoint: GET /api/user/api-keys/status                                                             
                                                                                                                  
      Purpose: Check which API keys are configured (without revealing keys)                                       
                                                                                                                  
      interface APIKeysStatus {                                                                                   
        openai: boolean;  // true if key exists                                                                   
        anthropic: boolean;                                                                                       
        google: boolean;                                                                                          
      }                                                                                                           
                                                                                                                  
      2.3 New Endpoint: GET /api/models                                                                           
                                                                                                                  
      Purpose: List available models based on user tier                                                           
                                                                                                                  
      interface ModelInfo {                                                                                       
        id: string;  // e.g., '@cf/meta/llama-3.3-70b-instruct-fp8-fast'                                          
        name: string;  // Display name                                                                            
        provider: 'cloudflare' | 'openai' | 'anthropic' | 'google';                                               
        size: string;  // e.g., '8B', '70B', '120B'                                                               
        requires_api_key: boolean;                                                                                
        tier_required: 'free' | 'pro' | 'premium';                                                                
      }                                                                                                           
                                                                                                                  
      // Returns:                                                                                                 
      // - All Cloudflare models (always available)                                                               
      // - External models IF user has API key configured AND is PRO+                                             
                                                                                                                  
      2.4 Update Allegorical Service (allegorical.ts)                                                             
                                                                                                                  
      Changes:                                                                                                    
      1. Accept model and length_preference parameters                                                            
      2. Calculate max_tokens based on length preference:                                                         
        - shorter: 0.5x input tokens                                                                              
        - same: 1.0x input tokens                                                                                 
        - longer: 2.0x input tokens                                                                               
        - much_longer: 3.0x input tokens                                                                          
      3. Route to appropriate LLM provider:                                                                       
        - Cloudflare models â†’ env.AI.run()                                                                        
        - OpenAI â†’ Fetch to OpenAI API with decrypted key                                                         
        - Anthropic â†’ Fetch to Anthropic API                                                                      
        - Google â†’ Fetch to Gemini API                                                                            
                                                                                                                  
      Token Calculation Example:                                                                                  
      const inputTokens = estimateTokenCount(input_text);  // ~4 chars per token                                  
      const multipliers = { shorter: 0.5, same: 1.0, longer: 2.0, much_longer: 3.0 };                             
      const max_tokens = Math.min(                                                                                
        inputTokens * multipliers[length_preference],                                                             
        8192  // Cap at 8K tokens max                                                                             
      );                                                                                                          
                                                                                                                  
      ---                                                                                                         
      Phase 3: Frontend Changes                                                                                   
                                                                                                                  
      3.1 Update AllegoricalForm.tsx                                                                              
                                                                                                                  
      Add Two New Dropdowns:                                                                                      
                                                                                                                  
      1. Length Control (above "Transform" button)                                                                
      <select value={lengthPreference} onChange={...}>                                                            
        <option value="shorter">Shorter than original (50%)</option>                                              
        <option value="same">About the same length â‰ˆ</option>                                                     
        <option value="longer">Longer (2x) â¬†</option>                                                             
        <option value="much_longer">Much longer (3x) â¬†â¬†</option>                                                  
      </select>                                                                                                   
                                                                                                                  
      2. Model Selection (below persona/namespace/style)                                                          
      <select value={selectedModel} onChange={...}>                                                               
        <optgroup label="Cloudflare (Free)">                                                                      
          <option value="@cf/meta/llama-3.1-8b-instruct">Llama 3.1 8B (Current)</option>                          
          <option value="@cf/meta/llama-3.3-70b-instruct-fp8-fast">Llama 3.3 70B (Faster)</option>                
          <option value="@cf/meta/llama-4-scout-17b-16e-instruct">Llama 4 Scout 17B (Newest)</option>             
          <option value="@cf/openai/gpt-oss-20b">GPT-OSS 20B (High Quality)</option>                              
          <option value="@cf/qwen/qwq-32b">Qwen 32B (Reasoning)</option>                                          
        </optgroup>                                                                                               
                                                                                                                  
        {hasOpenAIKey && (                                                                                        
          <optgroup label="OpenAI (Your API Key)">                                                                
            <option value="openai:gpt-4o">GPT-4o</option>                                                         
            <option value="openai:gpt-4o-mini">GPT-4o Mini</option>                                               
          </optgroup>                                                                                             
        )}                                                                                                        
                                                                                                                  
        {hasAnthropicKey && (                                                                                     
          <optgroup label="Anthropic (Your API Key)">                                                             
            <option value="anthropic:claude-3-5-sonnet">Claude 3.5 Sonnet</option>                                
            <option value="anthropic:claude-3-5-haiku">Claude 3.5 Haiku</option>                                  
          </optgroup>                                                                                             
        )}                                                                                                        
                                                                                                                  
        {hasGoogleKey && (                                                                                        
          <optgroup label="Google (Your API Key)">                                                                
            <option value="google:gemini-2.0-flash">Gemini 2.0 Flash</option>                                     
            <option value="google:gemini-1.5-pro">Gemini 1.5 Pro</option>                                         
          </optgroup>                                                                                             
        )}                                                                                                        
      </select>                                                                                                   
                                                                                                                  
      Show "Configure API Keys" button (PRO+ only)                                                                
                                                                                                                  
      3.2 Create APIKeySettings.tsx Component                                                                     
                                                                                                                  
      Modal/Panel for API Key Management:                                                                         
      - Input fields for OpenAI, Anthropic, Google API keys                                                       
      - Mask keys with ***** when displaying existing keys                                                        
      - "Test Connection" button for each provider                                                                
      - "Save" encrypts and stores keys                                                                           
      - Only shown to PRO/PREMIUM/ADMIN users                                                                     
                                                                                                                  
      3.3 Update cloud-api-client.ts                                                                              
                                                                                                                  
      Add Methods:                                                                                                
      async setAPIKeys(keys: SetAPIKeysRequest): Promise<void>                                                    
      async getAPIKeysStatus(): Promise<APIKeysStatus>                                                            
      async getAvailableModels(): Promise<ModelInfo[]>                                                            
                                                                                                                  
      ---                                                                                                         
      Phase 4: Model Provider Integrations                                                                        
                                                                                                                  
      4.1 OpenAI Integration                                                                                      
                                                                                                                  
      // src/services/llm-providers/openai.ts                                                                     
      export async function callOpenAI(                                                                           
        model: string,  // 'gpt-4o', 'gpt-4o-mini'                                                                
        prompt: string,                                                                                           
        apiKey: string,                                                                                           
        maxTokens: number                                                                                         
      ): Promise<string> {                                                                                        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {                              
          method: 'POST',                                                                                         
          headers: {                                                                                              
            'Authorization': `Bearer ${apiKey}`,                                                                  
            'Content-Type': 'application/json'                                                                    
          },                                                                                                      
          body: JSON.stringify({                                                                                  
            model,                                                                                                
            messages: [{ role: 'user', content: prompt }],                                                        
            max_tokens: maxTokens,                                                                                
            temperature: 0.7                                                                                      
          })                                                                                                      
        });                                                                                                       
        // Parse and return response                                                                              
      }                                                                                                           
                                                                                                                  
      4.2 Anthropic Integration                                                                                   
                                                                                                                  
      // src/services/llm-providers/anthropic.ts                                                                  
      export async function callAnthropic(                                                                        
        model: string,  // 'claude-3-5-sonnet-20241022'                                                           
        prompt: string,                                                                                           
        apiKey: string,                                                                                           
        maxTokens: number                                                                                         
      ): Promise<string> {                                                                                        
        const response = await fetch('https://api.anthropic.com/v1/messages', {                                   
          method: 'POST',                                                                                         
          headers: {                                                                                              
            'x-api-key': apiKey,                                                                                  
            'anthropic-version': '2023-06-01',                                                                    
            'Content-Type': 'application/json'                                                                    
          },                                                                                                      
          body: JSON.stringify({                                                                                  
            model,                                                                                                
            messages: [{ role: 'user', content: prompt }],                                                        
            max_tokens: maxTokens,                                                                                
            temperature: 0.7                                                                                      
          })                                                                                                      
        });                                                                                                       
        // Parse and return response                                                                              
      }                                                                                                           
                                                                                                                  
      4.3 Google Gemini Integration                                                                               
                                                                                                                  
      // src/services/llm-providers/google.ts                                                                     
      export async function callGemini(                                                                           
        model: string,  // 'gemini-2.0-flash-exp', 'gemini-1.5-pro'                                               
        prompt: string,                                                                                           
        apiKey: string,                                                                                           
        maxTokens: number                                                                                         
      ): Promise<string> {                                                                                        
        const response = await fetch(                                                                             
          `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,       
          {                                                                                                       
            method: 'POST',                                                                                       
            headers: { 'Content-Type': 'application/json' },                                                      
            body: JSON.stringify({                                                                                
              contents: [{ parts: [{ text: prompt }] }],                                                          
              generationConfig: { maxOutputTokens: maxTokens, temperature: 0.7 }                                  
            })                                                                                                    
          }                                                                                                       
        );                                                                                                        
        // Parse and return response                                                                              
      }                                                                                                           
                                                                                                                  
      ---                                                                                                         
      Phase 5: Testing Strategy                                                                                   
                                                                                                                  
      5.1 Security Tests                                                                                          
                                                                                                                  
      - âœ… Verify API keys encrypted in database (not plain text)                                                  
      - âœ… Verify decryption requires correct user ID + JWT_SECRET                                                 
      - âœ… Test encryption/decryption roundtrip                                                                    
      - âœ… Verify non-PRO users cannot access API key endpoints                                                    
                                                                                                                  
      5.2 Functionality Tests                                                                                     
                                                                                                                  
      - âœ… Test each Cloudflare model in allegorical transform                                                     
      - âœ… Test length controls (shorter/same/longer/much_longer)                                                  
      - âœ… Test OpenAI integration with valid/invalid keys                                                         
      - âœ… Test Anthropic integration                                                                              
      - âœ… Test Google Gemini integration                                                                          
      - âœ… Verify model list updates when API keys added                                                           
                                                                                                                  
      5.3 UI/UX Tests                                                                                             
                                                                                                                  
      - âœ… Verify model dropdown shows correct options per tier                                                    
      - âœ… Verify length dropdown saves preference                                                                 
      - âœ… Test API key settings modal (PRO+ only)                                                                 
      - âœ… Test "Configure API Keys" button visibility                                                             
      - âœ… Verify key masking (show as *****)                                                                      
                                                                                                                  
      ---                                                                                                         
      Phase 6: Deployment Steps                                                                                   
                                                                                                                  
      6.1 Pre-Deployment                                                                                          
                                                                                                                  
      1. Run migration: npx wrangler d1 migrations apply npe-db                                                   
      2. Test encryption/decryption locally                                                                       
      3. Verify JWT_SECRET is set: npx wrangler secret list                                                       
                                                                                                                  
      6.2 Deployment                                                                                              
                                                                                                                  
      1. Deploy Workers API: npx wrangler deploy                                                                  
      2. Build frontend: npm run build                                                                            
      3. Deploy frontend: npx wrangler pages deploy                                                               
                                                                                                                  
      6.3 Post-Deployment Verification                                                                            
                                                                                                                  
      1. Test as FREE user â†’ only Cloudflare models visible                                                       
      2. Upgrade test user to PRO â†’ verify API key settings visible                                               
      3. Add OpenAI key â†’ verify GPT models appear in dropdown                                                    
      4. Test allegorical transform with each model                                                               
      5. Verify length controls work correctly                                                                    
                                                                                                                  
      ---                                                                                                         
      Estimated Effort                                                                                            
                                                                                                                  
      Backend: ~6-8 hours                                                                                         
      - Migration (30 min)                                                                                        
      - Encryption utils (1 hour)                                                                                 
      - API key endpoints (2 hours)                                                                               
      - Model routing logic (2 hours)                                                                             
      - External provider integrations (2-3 hours)                                                                
                                                                                                                  
      Frontend: ~4-5 hours                                                                                        
      - Length dropdown (1 hour)                                                                                  
      - Model dropdown (1.5 hours)                                                                                
      - API key settings modal (2 hours)                                                                          
      - API client updates (30 min)                                                                               
                                                                                                                  
      Testing: ~2-3 hours                                                                                         
      - Security testing (1 hour)                                                                                 
      - Functionality testing (1-1.5 hours)                                                                       
      - UI/UX testing (30 min)                                                                                    
                                                                                                                  
      Total: ~12-16 hours                                                                                         
                                                                                                                  
      ---                                                                                                         
      Risks & Mitigations                                                                                         
                                                                                                                  
      Risk 1: External API costs                                                                                  
      - Mitigation: Only PRO+ users, clearly show pricing/usage warnings                                          
                                                                                                                  
      Risk 2: API key leakage                                                                                     
      - Mitigation: Strong encryption, never log keys, audit access                                               
                                                                                                                  
      Risk 3: Model quality variance                                                                              
      - Mitigation: Default to proven Llama 3.1, let users experiment                                             
                                                                                                                  
      Risk 4: Token limit mismatches                                                                              
      - Mitigation: Cap at 8K tokens max, handle errors gracefully                                                
                                                                                                                  
      ---                                                                                                         
      Future Enhancements (Out of Scope)                                                                          
                                                                                                                  
      - Extend model selection to Round-Trip, Maieutic, Quantum Reading                                           
      - Add cost tracking per transformation                                                                      
      - Add model performance metrics (speed, quality ratings)                                                    
      - Support additional providers (Mistral, DeepSeek, etc.)                                                    
      - Add streaming responses for longer generations                                                            
                                                                                                                  
      ---                                                                                                         
      Ready to implement when you approve! ðŸš€                                                                     

